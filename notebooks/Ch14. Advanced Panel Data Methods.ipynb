{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bbbc74f4",
   "metadata": {},
   "source": [
    "# 14. Advanced Panel Data Methods\n",
    "\n",
    ":::{important} Learning Objectives\n",
    ":class: dropdown\n",
    "By the end of this chapter, you should be able to:\n",
    "\n",
    "**14.1** Understand and apply the fixed effects (FE) estimator to control for unobserved heterogeneity in panel data.\n",
    "\n",
    "**14.2** Understand and apply the random effects (RE) estimator and when it is appropriate.\n",
    "\n",
    "**14.3** Use the correlated random effects (CRE) approach to test and relax RE assumptions.\n",
    "\n",
    "**14.4** Apply panel data methods to policy analysis and program evaluation.\n",
    "\n",
    "**14.5** Extend panel data methods to other data structures including repeated cross sections.\n",
    ":::\n",
    "\n",
    "Welcome to Chapter 14, where we delve deeper into panel data econometrics. Building on the first-differencing methods from Chapter 13, we now explore the **fixed effects** and **random effects** estimators, two workhorses of applied panel data analysis.\n",
    "\n",
    "These advanced methods allow us to:\n",
    "- Control for time-invariant unobserved heterogeneity\n",
    "- Choose between FE and RE based on testable assumptions\n",
    "- Implement robust inference with clustered standard errors\n",
    "- Handle unbalanced panels and complex data structures\n",
    "\n",
    "The choice between fixed effects and random effects has important implications for both efficiency and consistency of our estimates. We'll learn when each method is appropriate and how to test between them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "694a42c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install matplotlib numpy pandas statsmodels wooldridge linearmodels scipy -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "759df499",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import statsmodels.formula.api as smf\n",
    "import wooldridge as wool\n",
    "from IPython.display import display\n",
    "from linearmodels import PanelOLS, RandomEffects\n",
    "\n",
    "# Set plotting style\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_palette(\"husl\")\n",
    "plt.rcParams[\"figure.figsize\"] = [10, 6]\n",
    "plt.rcParams[\"font.size\"] = 11\n",
    "plt.rcParams[\"axes.titlesize\"] = 14\n",
    "plt.rcParams[\"axes.labelsize\"] = 12"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7862a54",
   "metadata": {},
   "source": [
    "## 14.1 Fixed Effects Estimation\n",
    "\n",
    "The **fixed effects** (FE) estimator, also called the **within estimator**, removes the unobserved individual effect $a_i$ by de-meaning all variables. This is one of the most widely used panel data estimators in economics.\n",
    "\n",
    "### The Fixed Effects Model\n",
    "\n",
    "Consider the standard panel data model with unobserved heterogeneity:\n",
    "\n",
    "$$ y_{it} = \\beta_1 x_{1,it} + \\beta_2 x_{2,it} + \\ldots + \\beta_k x_{k,it} + a_i + u_{it} $$\n",
    "\n",
    "where:\n",
    "- $a_i$ = individual-specific unobserved effect (time-invariant)\n",
    "- $u_{it}$ = idiosyncratic error (varies over $i$ and $t$)\n",
    "- The key problem: $a_i$ may be correlated with the $x$ variables\n",
    "\n",
    "### The Within Transformation\n",
    "\n",
    "The FE estimator eliminates $a_i$ by subtracting the individual-specific time average from each variable:\n",
    "\n",
    "$$ \\ddot{y}_{it} = y_{it} - \\bar{y}_i = \\beta_1 \\ddot{x}_{1,it} + \\ldots + \\beta_k \\ddot{x}_{k,it} + \\ddot{u}_{it} $$\n",
    "\n",
    "where $\\bar{y}_i = T_i^{-1} \\sum_{t=1}^{T_i} y_{it}$ is the time average for individual $i$, and $\\ddot{y}_{it} = y_{it} - \\bar{y}_i$ is the de-meaned (or \"within\") transformation.\n",
    "\n",
    "Notice that $a_i$ has disappeared because $a_i - a_i = 0$!\n",
    "\n",
    "### Properties of the FE Estimator\n",
    "\n",
    "1. **Consistency**: FE is consistent even if $a_i$ is correlated with the $x$ variables\n",
    "2. **Strict exogeneity required**: $E(u_{it}|x_{i1}, \\ldots, x_{iT}, a_i) = 0$ for all $t$\n",
    "3. **Time-invariant variables**: Cannot estimate effects of variables that don't change over time\n",
    "4. **Standard errors**: Should be clustered at the individual level to account for serial correlation\n",
    "\n",
    "### Example 14.1: Effect of Job Training on Firm Productivity\n",
    "\n",
    "We'll analyze whether job training grants improve firm productivity using data on manufacturing firms. The outcome is the (log) scrap rate, and we control for unobserved firm characteristics that might affect both training and productivity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d1e17d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load job training panel data\n",
    "jtrain = wool.data(\"jtrain\")\n",
    "\n",
    "print(\"Dataset Information:\")\n",
    "print(f\"Total observations: {len(jtrain)}\")\n",
    "print(f\"Number of firms: {jtrain['fcode'].nunique()}\")\n",
    "print(f\"Years: {sorted(jtrain['year'].unique())}\")\n",
    "print(f\"Time periods per firm: {len(jtrain['year'].unique())}\")\n",
    "\n",
    "# Display variable descriptions\n",
    "print(\"\\nKey Variables:\")\n",
    "print(\"- lscrap: log(scrap rate) - our outcome variable\")\n",
    "print(\"- d88, d89: year dummies for 1988 and 1989\")\n",
    "print(\"- grant: =1 if firm received grant this year\")\n",
    "print(\"- grant_1: =1 if firm received grant last year\")\n",
    "print(\"- fcode: firm identifier\")\n",
    "\n",
    "# Show first observations for a few firms\n",
    "display(jtrain.head(15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0b12ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary statistics\n",
    "key_vars = [\"lscrap\", \"grant\", \"grant_1\", \"d88\", \"d89\"]\n",
    "print(\"Summary Statistics:\")\n",
    "display(jtrain[key_vars].describe().round(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1446c2a6",
   "metadata": {},
   "source": [
    "#### Manual Fixed Effects Estimation\n",
    "\n",
    "To understand FE intuitively, let's first estimate it manually by de-meaning the variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a422e215",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up panel structure\n",
    "jtrain_panel = jtrain.copy()\n",
    "jtrain_panel[\"entity\"] = jtrain_panel[\"fcode\"]\n",
    "jtrain_panel = jtrain_panel.set_index([\"fcode\", \"year\"])\n",
    "\n",
    "# Manual computation: subtract entity (firm) means from each variable\n",
    "# The suffix '_w' denotes \"within\" (de-meaned) variables\n",
    "jtrain_panel[\"lscrap_w\"] = jtrain_panel[\"lscrap\"] - jtrain_panel.groupby(\"fcode\")[\n",
    "    \"lscrap\"\n",
    "].transform(\"mean\")\n",
    "jtrain_panel[\"d88_w\"] = jtrain_panel[\"d88\"] - jtrain_panel.groupby(\"fcode\")[\n",
    "    \"d88\"\n",
    "].transform(\"mean\")\n",
    "jtrain_panel[\"d89_w\"] = jtrain_panel[\"d89\"] - jtrain_panel.groupby(\"fcode\")[\n",
    "    \"d89\"\n",
    "].transform(\"mean\")\n",
    "jtrain_panel[\"grant_w\"] = jtrain_panel[\"grant\"] - jtrain_panel.groupby(\"fcode\")[\n",
    "    \"grant\"\n",
    "].transform(\"mean\")\n",
    "jtrain_panel[\"grant_1_w\"] = jtrain_panel[\"grant_1\"] - jtrain_panel.groupby(\"fcode\")[\n",
    "    \"grant_1\"\n",
    "].transform(\"mean\")\n",
    "\n",
    "print(\"Manual de-meaning completed\")\n",
    "print(\"\\nExample: First firm's de-meaned values\")\n",
    "first_firm = jtrain_panel.index.get_level_values(0).unique()[0]\n",
    "display(jtrain_panel.loc[first_firm, [\"lscrap\", \"lscrap_w\", \"grant\", \"grant_w\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfaeb838",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimate FE model manually using OLS on de-meaned data\n",
    "# Note: no intercept (0 +) because de-meaned data has mean zero\n",
    "model_manual = smf.ols(\n",
    "    formula=\"lscrap_w ~ 0 + d88_w + d89_w + grant_w + grant_1_w\",\n",
    "    data=jtrain_panel,\n",
    ")\n",
    "results_manual = model_manual.fit()\n",
    "\n",
    "print(\"MANUAL FIXED EFFECTS ESTIMATION\")\n",
    "print(\"=\" * 70)\n",
    "print(\"(Estimated using OLS on de-meaned variables)\")\n",
    "print()\n",
    "\n",
    "table_manual = pd.DataFrame(\n",
    "    {\n",
    "        \"Coefficient\": results_manual.params,\n",
    "        \"Std. Error\": results_manual.bse,\n",
    "        \"t-statistic\": results_manual.tvalues,\n",
    "        \"p-value\": results_manual.pvalues,\n",
    "    },\n",
    ")\n",
    "display(table_manual.round(4))\n",
    "print(f\"\\nR-squared (within): {results_manual.rsquared:.4f}\")\n",
    "print(f\"Observations: {int(results_manual.nobs)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a230aefd",
   "metadata": {},
   "source": [
    "#### Automatic Fixed Effects Estimation\n",
    "\n",
    "Now let's use the specialized `PanelOLS` estimator with `EntityEffects`, which handles everything automatically:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46e6647a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Automatic FE estimation using linearmodels\n",
    "# EntityEffects automatically includes individual fixed effects\n",
    "# TimeEffects automatically includes time fixed effects\n",
    "model_auto = PanelOLS.from_formula(\n",
    "    formula=\"lscrap ~ d88 + d89 + grant + grant_1 + EntityEffects\",\n",
    "    data=jtrain_panel,\n",
    ")\n",
    "results_auto = model_auto.fit(cov_type=\"clustered\", cluster_entity=True)\n",
    "\n",
    "print(\"\\nAUTOMATIC FIXED EFFECTS ESTIMATION\")\n",
    "print(\"=\" * 70)\n",
    "print(\"(Using PanelOLS with EntityEffects and clustered SEs)\")\n",
    "print()\n",
    "\n",
    "table_auto = pd.DataFrame(\n",
    "    {\n",
    "        \"Coefficient\": results_auto.params,\n",
    "        \"Std. Error\": results_auto.std_errors,\n",
    "        \"t-statistic\": results_auto.tstats,\n",
    "        \"p-value\": results_auto.pvalues,\n",
    "    },\n",
    ")\n",
    "display(table_auto.round(4))\n",
    "print(f\"\\nR-squared (within): {results_auto.rsquared_within:.4f}\")\n",
    "print(f\"R-squared (overall): {results_auto.rsquared_overall:.4f}\")\n",
    "print(f\"Observations: {results_auto.nobs}\")\n",
    "print(f\"Entities (firms): {results_auto.entity_info['total']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7b233ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare manual and automatic estimates\n",
    "print(\"\\nCOMPARISON: Manual vs Automatic FE Estimates\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "comparison = pd.DataFrame(\n",
    "    {\n",
    "        \"Manual FE\": results_manual.params,\n",
    "        \"Automatic FE\": results_auto.params,\n",
    "        \"Difference\": results_manual.params - results_auto.params,\n",
    "    },\n",
    ")\n",
    "display(comparison.round(6))\n",
    "\n",
    "print(\"\\nNote: Coefficients are identical (differences due to rounding).\")\n",
    "print(\"Standard errors differ because automatic FE uses clustered SEs.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f14ba862",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interpretation of results\n",
    "print(\"\\nINTERPRETATION OF FIXED EFFECTS ESTIMATES:\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "grant_coef = results_auto.params[\"grant\"]\n",
    "grant_se = results_auto.std_errors[\"grant\"]\n",
    "grant_1_coef = results_auto.params[\"grant_1\"]\n",
    "\n",
    "print(f\"\\n1. Current Year Grant Effect: {grant_coef:.4f}\")\n",
    "if abs(grant_coef / grant_se) < 1.96:\n",
    "    print(\n",
    "        \"   The grant has NO statistically significant effect on scrap rates this year\",\n",
    "    )\n",
    "    print(\n",
    "        f\"   (t-stat = {grant_coef / grant_se:.2f}, p-value = {results_auto.pvalues['grant']:.3f})\"\n",
    "    )\n",
    "else:\n",
    "    print(\n",
    "        f\"   The grant {'reduces' if grant_coef < 0 else 'increases'} log(scrap) by {abs(grant_coef):.4f}\",\n",
    "    )\n",
    "    print(\n",
    "        f\"   This is approximately a {100 * abs(grant_coef):.2f}% change in scrap rates\"\n",
    "    )\n",
    "\n",
    "print(f\"\\n2. Lagged Grant Effect (grant_1): {grant_1_coef:.4f}\")\n",
    "print(\n",
    "    f\"   Receiving a grant LAST year {'reduces' if grant_1_coef < 0 else 'increases'} log(scrap) by {abs(grant_1_coef):.4f}\",\n",
    ")\n",
    "print(\n",
    "    f\"   This is approximately a {100 * abs(grant_1_coef):.2f}% change in scrap rates\"\n",
    ")\n",
    "print(\"   (The effect may take time to materialize as workers apply new skills)\")\n",
    "\n",
    "print(\"\\n3. Firm Fixed Effects:\")\n",
    "print(\"   The model controls for all time-invariant firm characteristics:\")\n",
    "print(\"   - Management quality\")\n",
    "print(\"   - Firm culture and organization\")\n",
    "print(\"   - Geographic location\")\n",
    "print(\"   - Industry-specific factors\")\n",
    "print(\"   - Any other unobserved factors that don't change over time\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dbcabf6",
   "metadata": {},
   "source": [
    "### Visualizing the Fixed Effects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42cd7c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize variation in scrap rates across firms and over time\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Panel A: Variation across firms (box plots)\n",
    "firm_means = jtrain.groupby(\"fcode\")[\"lscrap\"].mean().sort_values()\n",
    "top_10_firms = firm_means.head(10).index\n",
    "bottom_10_firms = firm_means.tail(10).index\n",
    "selected_firms = list(top_10_firms) + list(bottom_10_firms)\n",
    "\n",
    "jtrain_selected = jtrain[jtrain[\"fcode\"].isin(selected_firms)]\n",
    "jtrain_selected[\"firm_category\"] = jtrain_selected[\"fcode\"].apply(\n",
    "    lambda x: \"Low scrap\" if x in top_10_firms else \"High scrap\",\n",
    ")\n",
    "\n",
    "axes[0].boxplot(\n",
    "    [\n",
    "        jtrain_selected[jtrain_selected[\"firm_category\"] == \"Low scrap\"][\"lscrap\"],\n",
    "        jtrain_selected[jtrain_selected[\"firm_category\"] == \"High scrap\"][\"lscrap\"],\n",
    "    ],\n",
    "    labels=[\"Low Scrap Firms\", \"High Scrap Firms\"],\n",
    ")\n",
    "axes[0].set_ylabel(\"Log(Scrap Rate)\")\n",
    "axes[0].set_title(\"Cross-Sectional Variation: Between Firms\")\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Panel B: Within-firm variation over time (selected firms)\n",
    "for firm in list(top_10_firms)[:3]:\n",
    "    firm_data = jtrain[jtrain[\"fcode\"] == firm].sort_values(\"year\")\n",
    "    axes[1].plot(\n",
    "        firm_data[\"year\"], firm_data[\"lscrap\"], marker=\"o\", label=f\"Firm {firm}\"\n",
    "    )\n",
    "\n",
    "axes[1].set_xlabel(\"Year\")\n",
    "axes[1].set_ylabel(\"Log(Scrap Rate)\")\n",
    "axes[1].set_title(\"Within-Firm Variation: Over Time\")\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.suptitle(\n",
    "    \"Fixed Effects Uses Within-Firm Variation (Right Panel)\", fontweight=\"bold\"\n",
    ")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "828f7290",
   "metadata": {},
   "source": [
    "## 14.2 Random Effects Estimation\n",
    "\n",
    "The **random effects** (RE) estimator is a **generalized least squares** (GLS) estimator that can be more efficient than FE when the unobserved effect is uncorrelated with the explanatory variables.\n",
    "\n",
    "### The Random Effects Model\n",
    "\n",
    "The RE model assumes:\n",
    "\n",
    "$$ y_{it} = \\beta_0 + \\beta_1 x_{1,it} + \\ldots + \\beta_k x_{k,it} + a_i + u_{it} $$\n",
    "\n",
    "**Key RE assumption**: $E(a_i | x_{i1}, \\ldots, x_{iT}) = \\beta_0$\n",
    "\n",
    "This means $a_i$ is **uncorrelated** with all $x$ variables. This is a strong assumption!\n",
    "\n",
    "### Why Random Effects?\n",
    "\n",
    "**Efficiency**: If the RE assumption holds, RE is more efficient than FE\n",
    "**Time-invariant variables**: RE can estimate effects of variables that don't vary over time\n",
    "**Between variation**: RE uses both within and between variation\n",
    "\n",
    "### The RE Transformation\n",
    "\n",
    "RE uses a **quasi-demeaning** transformation:\n",
    "\n",
    "$$ y_{it} - \\theta \\bar{y}_i = \\beta_0(1-\\theta) + \\beta_1(x_{1,it} - \\theta \\bar{x}_{1,i}) + \\ldots + v_{it} $$\n",
    "\n",
    "where:\n",
    "- $\\theta = 1 - \\sqrt{\\sigma_u^2 / (\\sigma_u^2 + T\\sigma_a^2)}$\n",
    "- $\\theta \\in [0, 1]$ depending on the relative importance of $a_i$ vs $u_{it}$\n",
    "- If $\\theta = 1$: RE reduces to FE (full de-meaning)\n",
    "- If $\\theta = 0$: RE reduces to pooled OLS (no de-meaning)\n",
    "\n",
    "### Example 14.2: Wage Equation with Time-Varying Education Returns\n",
    "\n",
    "We'll estimate the returns to education, marriage, and union membership using a panel of male workers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "928dd1bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load wage panel data\n",
    "wagepan = wool.data(\"wagepan\")\n",
    "\n",
    "print(\"Dataset Information:\")\n",
    "print(f\"Total observations: {len(wagepan)}\")\n",
    "print(f\"Number of individuals: {wagepan['nr'].nunique()}\")\n",
    "print(f\"Years: {sorted(wagepan['year'].unique())}\")\n",
    "print(f\"Observations per person: {len(wagepan) / wagepan['nr'].nunique():.1f}\")\n",
    "\n",
    "print(\"\\nKey Variables:\")\n",
    "print(\"- lwage: log(wage)\")\n",
    "print(\"- educ: years of education (time-invariant for most)\")\n",
    "print(\"- married: =1 if married\")\n",
    "print(\"- union: =1 if union member\")\n",
    "print(\"- nr: person identifier\")\n",
    "\n",
    "display(wagepan.head(12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39c5fbad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up panel structure\n",
    "wagepan_panel = wagepan.set_index([\"nr\", \"year\"], drop=False)\n",
    "\n",
    "# Summary statistics\n",
    "print(\"Summary Statistics:\")\n",
    "display(wagepan[[\"lwage\", \"educ\", \"married\", \"union\", \"exper\"]].describe().round(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16f96e55",
   "metadata": {},
   "source": [
    "We want to allow education returns to vary by year (perhaps due to skill-biased technological change):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceeeb7d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fixed Effects model with time-varying education returns\n",
    "# C(year)*educ creates interactions between year dummies and education\n",
    "# year is already a column since we used drop=False in set_index\n",
    "fe_model = PanelOLS.from_formula(\n",
    "    formula=\"lwage ~ married + union + C(year)*educ + EntityEffects\",\n",
    "    data=wagepan_panel,\n",
    "    drop_absorbed=True,  # Don't show individual dummies\n",
    ")\n",
    "fe_results = fe_model.fit(cov_type=\"clustered\", cluster_entity=True)\n",
    "\n",
    "print(\"FIXED EFFECTS ESTIMATION: Time-Varying Returns to Education\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "fe_table = pd.DataFrame(\n",
    "    {\n",
    "        \"Coefficient\": fe_results.params,\n",
    "        \"Std. Error\": fe_results.std_errors,\n",
    "        \"t-statistic\": fe_results.tstats,\n",
    "        \"p-value\": fe_results.pvalues,\n",
    "    },\n",
    ")\n",
    "display(fe_table.round(4))\n",
    "print(f\"\\nR-squared (within): {fe_results.rsquared_within:.4f}\")\n",
    "print(f\"Observations: {fe_results.nobs}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c6ee602",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interpretation\n",
    "print(\"\\nINTERPRETATION OF FE RESULTS:\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "married_coef = fe_results.params[\"married\"]\n",
    "union_coef = fe_results.params[\"union\"]\n",
    "\n",
    "print(f\"\\n1. Marriage Premium: {married_coef:.4f}\")\n",
    "print(f\"   Being married increases log(wage) by {married_coef:.4f}\")\n",
    "print(f\"   Approximately {100 * married_coef:.2f}% higher wages for married men\")\n",
    "\n",
    "print(f\"\\n2. Union Premium: {union_coef:.4f}\")\n",
    "print(f\"   Union membership increases log(wage) by {union_coef:.4f}\")\n",
    "print(f\"   Approximately {100 * union_coef:.2f}% higher wages for union members\")\n",
    "\n",
    "print(\"\\n3. Education Returns by Year:\")\n",
    "print(\"   Base year return captured by year fixed effects\")\n",
    "print(\"   Interaction terms show how returns changed over time\")\n",
    "\n",
    "# Extract education*year interactions\n",
    "educ_interactions = {\n",
    "    k: v for k, v in fe_results.params.items() if \"educ\" in k and \":\" in k\n",
    "}\n",
    "if educ_interactions:\n",
    "    print(\"\\n   Year-specific changes in education returns:\")\n",
    "    for term, coef in educ_interactions.items():\n",
    "        print(f\"   {term}: {coef:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d4f3689",
   "metadata": {},
   "source": [
    "## 14.3 The Correlated Random Effects Approach\n",
    "\n",
    "The **Correlated Random Effects** (CRE) approach, developed by Chamberlain (1982) and Mundlak (1978), provides a middle ground between FE and RE. It allows correlation between $a_i$ and the $x$ variables in a flexible way.\n",
    "\n",
    "### The CRE Specification\n",
    "\n",
    "The key idea: model the correlation between $a_i$ and $x_{it}$ explicitly:\n",
    "\n",
    "$$ a_i = \\psi_0 + \\psi_1 \\bar{x}_{1,i} + \\psi_2 \\bar{x}_{2,i} + \\ldots + \\psi_k \\bar{x}_{k,i} + r_i $$\n",
    "\n",
    "where $\\bar{x}_{j,i} = T_i^{-1} \\sum_{t=1}^{T_i} x_{j,it}$ is the time average of variable $j$ for individual $i$.\n",
    "\n",
    "Substituting into the original model:\n",
    "\n",
    "$$ y_{it} = \\beta_0 + \\beta_1 x_{1,it} + \\ldots + \\beta_k x_{k,it} + \\psi_1 \\bar{x}_{1,i} + \\ldots + \\psi_k \\bar{x}_{k,i} + r_i + u_{it} $$\n",
    "\n",
    "Now $r_i$ is uncorrelated with all $x$ variables (by construction), so we can use RE methods!\n",
    "\n",
    "### Interpretation of CRE Coefficients\n",
    "\n",
    "- $\\beta_j$ = **within effect** (same as FE estimate)\n",
    "- $\\beta_j + \\psi_j$ = **overall effect** including between variation\n",
    "- $\\psi_j$ = difference between overall and within effects\n",
    "- If $\\psi_j = 0$: no correlation between $a_i$ and $x_j$ (RE assumption holds)\n",
    "\n",
    "### Example: CRE Wage Equation\n",
    "\n",
    "Let's estimate the wage equation using CRE to test whether marriage and union status are correlated with unobserved ability ($a_i$):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cae356fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for CRE\n",
    "wagepan_cre = wagepan.copy()\n",
    "wagepan_cre[\"t\"] = wagepan_cre[\"year\"]\n",
    "wagepan_cre[\"entity\"] = wagepan_cre[\"nr\"]\n",
    "\n",
    "# Create time-averages (group means) for time-varying variables\n",
    "# The suffix '_b' denotes \"between\" (time average)\n",
    "wagepan_cre[\"married_b\"] = wagepan_cre.groupby(\"nr\")[\"married\"].transform(\"mean\")\n",
    "wagepan_cre[\"union_b\"] = wagepan_cre.groupby(\"nr\")[\"union\"].transform(\"mean\")\n",
    "\n",
    "# Set panel index, keeping year as column for formulas\n",
    "wagepan_cre = wagepan_cre.set_index([\"nr\", \"year\"], drop=False)\n",
    "\n",
    "print(\"Created time-averaged variables:\")\n",
    "print(\"married_b: time average of married status for each person\")\n",
    "print(\"union_b: time average of union status for each person\")\n",
    "print(\"\\nFirst few observations:\")\n",
    "display(wagepan_cre[[\"lwage\", \"married\", \"married_b\", \"union\", \"union_b\"]].head(12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de2e4d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimate CRE model using Random Effects\n",
    "# Include both the original variables AND their time averages\n",
    "cre_model = RandomEffects.from_formula(\n",
    "    formula=\"lwage ~ married + union + educ + black + hisp + married_b + union_b\",\n",
    "    data=wagepan_cre,\n",
    ")\n",
    "cre_results = cre_model.fit(cov_type=\"clustered\", cluster_entity=True)\n",
    "\n",
    "print(\"CORRELATED RANDOM EFFECTS ESTIMATION\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "cre_table = pd.DataFrame(\n",
    "    {\n",
    "        \"Coefficient\": cre_results.params,\n",
    "        \"Std. Error\": cre_results.std_errors,\n",
    "        \"t-statistic\": cre_results.tstats,\n",
    "        \"p-value\": cre_results.pvalues,\n",
    "    },\n",
    ")\n",
    "display(cre_table.round(4))\n",
    "print(f\"\\nObservations: {cre_results.nobs}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9f48d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interpretation and hypothesis testing\n",
    "print(\"\\nINTERPRETATION OF CRE RESULTS:\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Within effects (same as FE)\n",
    "married_within = cre_results.params[\"married\"]\n",
    "union_within = cre_results.params[\"union\"]\n",
    "\n",
    "# Between effects (time-averaged variables)\n",
    "married_between = cre_results.params[\"married_b\"]\n",
    "union_between = cre_results.params[\"union_b\"]\n",
    "\n",
    "print(\"\\n1. WITHIN EFFECTS (changes over time):\")\n",
    "print(f\"   married: {married_within:.4f}\")\n",
    "print(f\"   Getting married increases wages by {100 * married_within:.2f}%\")\n",
    "print(f\"\\n   union: {union_within:.4f}\")\n",
    "print(f\"   Joining a union increases wages by {100 * union_within:.2f}%\")\n",
    "\n",
    "print(\"\\n2. BETWEEN EFFECTS (time-averaged):\")\n",
    "print(f\"   married_b: {married_between:.4f}\")\n",
    "if abs(married_between / cre_results.std_errors[\"married_b\"]) > 1.96:\n",
    "    print(\n",
    "        \"   Men who are married more often have \"\n",
    "        f\"{'higher' if married_between > 0 else 'lower'} unobserved ability\"\n",
    "    )\n",
    "    print(\"   (statistically significant at 5% level)\")\n",
    "else:\n",
    "    print(\"   No significant correlation with unobserved ability\")\n",
    "\n",
    "print(f\"\\n   union_b: {union_between:.4f}\")\n",
    "if abs(union_between / cre_results.std_errors[\"union_b\"]) > 1.96:\n",
    "    print(\n",
    "        \"   Men who are union members more often have \"\n",
    "        f\"{'higher' if union_between > 0 else 'lower'} unobserved ability\"\n",
    "    )\n",
    "    print(\"   (statistically significant at 5% level)\")\n",
    "else:\n",
    "    print(\"   No significant correlation with unobserved ability\")\n",
    "\n",
    "print(\"\\n3. TIME-INVARIANT VARIABLES:\")\n",
    "educ_coef = cre_results.params[\"educ\"]\n",
    "print(f\"   educ: {educ_coef:.4f}\")\n",
    "print(f\"   One additional year of education increases wages by {100 * educ_coef:.2f}%\")\n",
    "print(\"   (Cannot be estimated with FE because education doesn't vary)\")\n",
    "\n",
    "print(\"\\n4. TESTING THE RANDOM EFFECTS ASSUMPTION:\")\n",
    "print(\"   Null hypothesis: married_b = union_b = 0\")\n",
    "print(\"   (i.e., no correlation between time-averages and unobserved effect)\")\n",
    "if (\n",
    "    abs(married_between / cre_results.std_errors[\"married_b\"]) > 1.96\n",
    "    or abs(union_between / cre_results.std_errors[\"union_b\"]) > 1.96\n",
    "):\n",
    "    print(\"   REJECT: At least one time-average is significant\")\n",
    "    print(\"   → Standard RE assumption is violated\")\n",
    "    print(\"   → Should use FE or CRE instead of plain RE\")\n",
    "else:\n",
    "    print(\"   FAIL TO REJECT: Time-averages not significant\")\n",
    "    print(\"   → Standard RE assumption is plausible\")\n",
    "    print(\"   → Can use plain RE for efficiency\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "027c2421",
   "metadata": {},
   "source": [
    "### Hausman Test: FE vs RE\n",
    "\n",
    "The **Hausman test** compares FE and RE estimates to test whether the RE assumption holds:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8dd0989",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For demonstration: estimate plain RE (without time averages)\n",
    "re_model = RandomEffects.from_formula(\n",
    "    formula=\"lwage ~ married + union + educ + black + hisp\",\n",
    "    data=wagepan_cre,\n",
    ")\n",
    "re_results = re_model.fit(cov_type=\"clustered\", cluster_entity=True)\n",
    "\n",
    "print(\"PLAIN RANDOM EFFECTS (for comparison)\")\n",
    "print(\"=\" * 70)\n",
    "re_table = pd.DataFrame(\n",
    "    {\n",
    "        \"Coefficient\": re_results.params,\n",
    "        \"Std. Error\": re_results.std_errors,\n",
    "    },\n",
    ")\n",
    "display(re_table.round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a1a15f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare FE and RE estimates\n",
    "print(\"\\nCOMPARISON: Fixed Effects vs Random Effects\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Extract common coefficients\n",
    "common_vars = [\"married\", \"union\"]\n",
    "\n",
    "comparison_fe_re = pd.DataFrame(\n",
    "    {\n",
    "        \"Fixed Effects\": [fe_results.params[v] for v in common_vars],\n",
    "        \"Random Effects\": [re_results.params[v] for v in common_vars],\n",
    "        \"CRE (Within)\": [cre_results.params[v] for v in common_vars],\n",
    "        \"Difference (FE-RE)\": [\n",
    "            fe_results.params[v] - re_results.params[v] for v in common_vars\n",
    "        ],\n",
    "    },\n",
    "    index=common_vars,\n",
    ")\n",
    "\n",
    "display(comparison_fe_re.round(4))\n",
    "\n",
    "print(\"\\nINTERPRETATION:\")\n",
    "print(\"- FE and CRE give identical within estimates (as they should)\")\n",
    "print(\"- RE estimates differ from FE if unobserved heterogeneity is correlated with X\")\n",
    "print(\"- Large differences suggest RE assumption is violated → use FE or CRE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10993bc4",
   "metadata": {},
   "source": [
    "## 14.4 General Policy Analysis with Panel Data\n",
    "\n",
    "Panel data methods are particularly powerful for policy analysis. The FE estimator automatically controls for all time-invariant confounders, making it ideal for difference-in-differences designs and program evaluation.\n",
    "\n",
    "### Key Advantages for Policy Analysis\n",
    "\n",
    "1. **Control for selection bias**: Eliminates time-invariant confounders\n",
    "2. **Natural experiments**: Exploit policy changes that affect some units but not others\n",
    "3. **Difference-in-differences**: Built into FE through interaction terms\n",
    "4. **Robust inference**: Clustered standard errors account for serial correlation\n",
    "\n",
    "### Policy Analysis Framework\n",
    "\n",
    "Consider evaluating a policy that affects some units (treatment group) starting in period $T_0$:\n",
    "\n",
    "$$ y_{it} = \\beta_0 + \\delta \\cdot \\text{treat}_i \\cdot \\text{post}_t + a_i + \\gamma_t + u_{it} $$\n",
    "\n",
    "where:\n",
    "- $\\text{treat}_i$ = 1 for treatment group\n",
    "- $\\text{post}_t$ = 1 for periods $t \\geq T_0$\n",
    "- $\\delta$ = policy effect (DiD estimator)\n",
    "- $a_i$ = individual fixed effects\n",
    "- $\\gamma_t$ = time fixed effects\n",
    "\n",
    "### Example: Job Training Program Evaluation (Revisited)\n",
    "\n",
    "Let's revisit the job training example with a policy interpretation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8597ec1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create policy variables\n",
    "jtrain_policy = jtrain.copy()\n",
    "\n",
    "# Ever treated indicator\n",
    "jtrain_policy[\"ever_grant\"] = (\n",
    "    jtrain_policy.groupby(\"fcode\")[\"grant\"].transform(\"max\") == 1\n",
    ").astype(int)\n",
    "\n",
    "# Post-treatment indicator (after receiving grant)\n",
    "jtrain_policy[\"post_grant\"] = (\n",
    "    jtrain_policy.groupby(\"fcode\")[\"grant\"].transform(\"cumsum\") > 0\n",
    ").astype(int)\n",
    "\n",
    "print(\"Policy Analysis Setup:\")\n",
    "n_years = jtrain_policy[\"year\"].nunique()\n",
    "print(\n",
    "    f\"Firms ever receiving grants: {jtrain_policy.groupby('fcode')['ever_grant'].max().sum()}\"\n",
    ")\n",
    "print(f\"Firm-years with active grants: {jtrain_policy['grant'].sum()}\")\n",
    "print(f\"Firm-years post-grant: {jtrain_policy['post_grant'].sum()}\")\n",
    "\n",
    "# Set panel index but keep year as column (drop=False)\n",
    "jtrain_policy = jtrain_policy.set_index([\"fcode\", \"year\"], drop=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f6fd5cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimate policy effect using FE\n",
    "# Keep year as a column (drop=False in set_index) to use C(year)\n",
    "policy_model = PanelOLS.from_formula(\n",
    "    formula=\"lscrap ~ grant + grant_1 + C(year) + EntityEffects\",\n",
    "    data=jtrain_policy,\n",
    "    drop_absorbed=True,\n",
    ")\n",
    "policy_results = policy_model.fit(cov_type=\"clustered\", cluster_entity=True)\n",
    "\n",
    "print(\"POLICY EVALUATION: Job Training Grants\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "policy_table = pd.DataFrame(\n",
    "    {\n",
    "        \"Coefficient\": policy_results.params,\n",
    "        \"Std. Error\": policy_results.std_errors,\n",
    "        \"t-statistic\": policy_results.tstats,\n",
    "        \"p-value\": policy_results.pvalues,\n",
    "    },\n",
    ")\n",
    "display(policy_table.round(4))\n",
    "\n",
    "print(\"\\nPOLICY IMPLICATIONS:\")\n",
    "grant_effect = policy_results.params[\"grant\"]\n",
    "grant_1_effect = policy_results.params[\"grant_1\"]\n",
    "\n",
    "print(f\"\\n1. Immediate Effect: {grant_effect:.4f}\")\n",
    "print(\n",
    "    \"   The training program has \"\n",
    "    f\"{'a significant' if abs(grant_effect / policy_results.std_errors['grant']) > 1.96 else 'NO significant'} \"\n",
    "    \"immediate effect\"\n",
    ")\n",
    "\n",
    "print(f\"\\n2. Lagged Effect: {grant_1_effect:.4f}\")\n",
    "print(\n",
    "    f\"   One year after training, scrap rates \"\n",
    "    f\"{'decrease' if grant_1_effect < 0 else 'increase'} by {100 * abs(grant_1_effect):.2f}%\"\n",
    ")\n",
    "\n",
    "total_effect = grant_effect + grant_1_effect\n",
    "print(f\"\\n3. Cumulative Effect: {total_effect:.4f}\")\n",
    "print(\n",
    "    f\"   Over two years, the program \"\n",
    "    f\"{'reduces' if total_effect < 0 else 'increases'} scrap by {100 * abs(total_effect):.2f}%\"\n",
    ")\n",
    "\n",
    "print(\"\\n4. Cost-Benefit Analysis:\")\n",
    "print(\"   This estimate controls for:\")\n",
    "print(\"   - Firm-specific productivity levels\")\n",
    "print(\"   - Management quality\")\n",
    "print(\"   - Industry conditions\")\n",
    "print(\"   → More credible causal estimate than cross-sectional analysis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eefc665",
   "metadata": {},
   "source": [
    "## 14.5 Applying Panel Data Methods to Other Data Structures\n",
    "\n",
    "Panel data methods can be adapted to various data structures beyond traditional panels:\n",
    "\n",
    "### Repeated Cross Sections (Pseudo-Panels)\n",
    "\n",
    "When we have repeated cross sections but not true panel data, we can create **pseudo-panels** by:\n",
    "1. Grouping individuals into cohorts (e.g., by birth year, education)\n",
    "2. Calculating cohort-level averages\n",
    "3. Applying panel methods to cohort-level data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51181390",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstration with CPS data (repeated cross sections)\n",
    "cps = wool.data(\"cps78_85\")\n",
    "\n",
    "# Create cohorts based on age and education\n",
    "cps[\"cohort\"] = (\n",
    "    pd.cut(\n",
    "        cps[\"age\"], bins=[0, 30, 40, 50, 100], labels=[\"young\", \"mid\", \"senior\", \"old\"]\n",
    "    ).astype(str)\n",
    "    + \"_\"\n",
    "    + pd.cut(\n",
    "        cps[\"educ\"], bins=[0, 12, 16, 100], labels=[\"HS\", \"college\", \"grad\"]\n",
    "    ).astype(str)\n",
    ")\n",
    "\n",
    "# Create cohort-level panel\n",
    "cohort_panel = (\n",
    "    cps.groupby([\"cohort\", \"year\"])\n",
    "    .agg({\"lwage\": \"mean\", \"exper\": \"mean\", \"educ\": \"mean\"})\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# Set index but keep year as column for formulas\n",
    "cohort_panel = cohort_panel.set_index([\"cohort\", \"year\"], drop=False)\n",
    "\n",
    "print(\"Pseudo-Panel (Cohort-Level Data):\")\n",
    "print(f\"Number of cohorts: {cohort_panel.index.get_level_values(0).nunique()}\")\n",
    "print(f\"Time periods: {cohort_panel.index.get_level_values(1).nunique()}\")\n",
    "display(cohort_panel.head(12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "934cb048",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimate FE model on cohort-level data\n",
    "# year should be a column for C(year) to work\n",
    "cohort_fe = PanelOLS.from_formula(\n",
    "    formula=\"lwage ~ exper + C(year) + EntityEffects\",\n",
    "    data=cohort_panel,\n",
    ")\n",
    "cohort_results = cohort_fe.fit()\n",
    "\n",
    "print(\"\\nPSEUDO-PANEL RESULTS (Cohort-Level FE)\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "cohort_table = pd.DataFrame(\n",
    "    {\n",
    "        \"Coefficient\": cohort_results.params,\n",
    "        \"Std. Error\": cohort_results.std_errors,\n",
    "        \"t-statistic\": cohort_results.tstats,\n",
    "    },\n",
    ")\n",
    "display(cohort_table.round(4))\n",
    "\n",
    "print(\"\\nNote: This approach works when:\")\n",
    "print(\"- Cohorts are large (to reduce measurement error in averages)\")\n",
    "print(\"- Cohort composition is stable over time\")\n",
    "print(\"- Treatment varies at the cohort level\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d36b5bd4",
   "metadata": {},
   "source": [
    "### Clustering and Standard Errors\n",
    "\n",
    "With panel data, errors are typically correlated within entities over time. We should always use **clustered standard errors**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd06e4eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate impact of clustering\n",
    "print(\"IMPORTANCE OF CLUSTERED STANDARD ERRORS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Estimate without clustering (WRONG)\n",
    "fe_no_cluster = PanelOLS.from_formula(\n",
    "    formula=\"lwage ~ married + union + C(year) + EntityEffects\",\n",
    "    data=wagepan_panel,\n",
    "    drop_absorbed=True,\n",
    ")\n",
    "results_no_cluster = fe_no_cluster.fit(cov_type=\"unadjusted\")\n",
    "\n",
    "# Estimate with clustering (CORRECT)\n",
    "fe_cluster = PanelOLS.from_formula(\n",
    "    formula=\"lwage ~ married + union + C(year) + EntityEffects\",\n",
    "    data=wagepan_panel,\n",
    "    drop_absorbed=True,\n",
    ")\n",
    "results_cluster = fe_cluster.fit(cov_type=\"clustered\", cluster_entity=True)\n",
    "\n",
    "# Compare standard errors\n",
    "se_comparison = pd.DataFrame(\n",
    "    {\n",
    "        \"No Clustering (WRONG)\": results_no_cluster.std_errors,\n",
    "        \"With Clustering (CORRECT)\": results_cluster.std_errors,\n",
    "        \"Ratio (Clustered/Unclustered)\": results_cluster.std_errors\n",
    "        / results_no_cluster.std_errors,\n",
    "    },\n",
    ")\n",
    "\n",
    "print(\"\\nStandard Error Comparison:\")\n",
    "display(se_comparison.round(4))\n",
    "\n",
    "print(\"\\nKEY INSIGHT:\")\n",
    "print(\"- Clustered SEs are typically LARGER than unclustered SEs\")\n",
    "print(\"- Failing to cluster leads to overconfident inference\")\n",
    "print(\"- t-statistics are smaller with clustering (more conservative)\")\n",
    "print(\"- ALWAYS use clustered SEs with panel data!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6786115d",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This chapter introduced advanced panel data methods for controlling unobserved heterogeneity:\n",
    "\n",
    "1. **Fixed Effects (FE)**:\n",
    "   - Eliminates $a_i$ by de-meaning (within transformation)\n",
    "   - Consistent even if $a_i$ is correlated with $x$\n",
    "   - Cannot estimate effects of time-invariant variables\n",
    "   - Should always use clustered standard errors\n",
    "\n",
    "2. **Random Effects (RE)**:\n",
    "   - More efficient than FE when $a_i$ is uncorrelated with $x$\n",
    "   - Can estimate effects of time-invariant variables\n",
    "   - Uses quasi-demeaning (partial de-meaning)\n",
    "   - Requires strong exogeneity assumption\n",
    "\n",
    "3. **Correlated Random Effects (CRE)**:\n",
    "   - Models correlation between $a_i$ and $x$ explicitly\n",
    "   - Gives FE estimates as within effects\n",
    "   - Can test RE assumption\n",
    "   - Allows estimation of time-invariant variable effects\n",
    "\n",
    "4. **Policy Analysis**:\n",
    "   - FE ideal for difference-in-differences designs\n",
    "   - Controls for time-invariant selection bias\n",
    "   - Clustered SEs crucial for valid inference\n",
    "\n",
    "5. **Extensions**:\n",
    "   - Pseudo-panels for repeated cross sections\n",
    "   - Robust inference with clustering\n",
    "   - Unbalanced panels handled naturally\n",
    "\n",
    "**Key Takeaway**: The choice between FE, RE, and CRE depends on whether $a_i$ is correlated with the explanatory variables. When in doubt, use FE or CRE for robustness.\n",
    "\n",
    "**Next Steps**: Chapter 15 introduces instrumental variables methods for handling endogeneity beyond unobserved heterogeneity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56cc3e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visual summary\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "ax.axis(\"off\")\n",
    "\n",
    "# Title\n",
    "ax.text(\n",
    "    0.5,\n",
    "    0.95,\n",
    "    \"Chapter 14: Fixed vs Random Effects Decision Tree\",\n",
    "    ha=\"center\",\n",
    "    fontsize=16,\n",
    "    fontweight=\"bold\",\n",
    ")\n",
    "\n",
    "# Question 1\n",
    "ax.text(\n",
    "    0.5, 0.85, \"Is aᵢ correlated with xᵢₜ?\", ha=\"center\", fontsize=12, fontweight=\"bold\"\n",
    ")\n",
    "\n",
    "# Branch: No correlation\n",
    "ax.add_patch(\n",
    "    plt.Rectangle((0.05, 0.65), 0.35, 0.15, fill=True, alpha=0.3, color=\"green\")\n",
    ")\n",
    "ax.text(0.225, 0.78, \"NO (or plausible)\", ha=\"center\", fontsize=10, fontweight=\"bold\")\n",
    "ax.text(0.225, 0.73, \"Use Random Effects\", ha=\"center\", fontsize=11)\n",
    "ax.text(0.225, 0.68, \"✓ More efficient\", ha=\"center\", fontsize=8)\n",
    "\n",
    "# Branch: Yes correlation\n",
    "ax.add_patch(plt.Rectangle((0.6, 0.65), 0.35, 0.15, fill=True, alpha=0.3, color=\"red\"))\n",
    "ax.text(0.775, 0.78, \"YES (or uncertain)\", ha=\"center\", fontsize=10, fontweight=\"bold\")\n",
    "ax.text(0.775, 0.73, \"Use Fixed Effects or CRE\", ha=\"center\", fontsize=11)\n",
    "ax.text(0.775, 0.68, \"✓ Consistent\", ha=\"center\", fontsize=8)\n",
    "\n",
    "# CRE box\n",
    "ax.add_patch(\n",
    "    plt.Rectangle((0.35, 0.45), 0.3, 0.15, fill=True, alpha=0.3, color=\"purple\")\n",
    ")\n",
    "ax.text(\n",
    "    0.5, 0.58, \"Correlated Random Effects\", ha=\"center\", fontsize=11, fontweight=\"bold\"\n",
    ")\n",
    "ax.text(0.5, 0.53, \"• Test RE assumption\", ha=\"center\", fontsize=9)\n",
    "ax.text(0.5, 0.48, \"• Get FE + time-invariant effects\", ha=\"center\", fontsize=9)\n",
    "\n",
    "# Bottom section: When to use what\n",
    "methods = [\"Fixed Effects\", \"Random Effects\", \"CRE\", \"Pooled OLS\"]\n",
    "uses = [\n",
    "    \"Default choice\\nRobust to correlation\",\n",
    "    \"Time-invariant vars\\nIf RE assumption holds\",\n",
    "    \"Test assumptions\\nGet both FE and RE info\",\n",
    "    \"No unobserved\\nheterogeneity (rare)\",\n",
    "]\n",
    "colors = [\"red\", \"green\", \"purple\", \"gray\"]\n",
    "\n",
    "for i, (method, use, color) in enumerate(zip(methods, uses, colors, strict=False)):\n",
    "    x_pos = 0.125 + i * 0.22\n",
    "    ax.add_patch(\n",
    "        plt.Rectangle(\n",
    "            (x_pos - 0.08, 0.15), 0.16, 0.22, fill=True, alpha=0.2, color=color\n",
    "        )\n",
    "    )\n",
    "    ax.text(x_pos, 0.32, method, ha=\"center\", fontsize=9, fontweight=\"bold\")\n",
    "    ax.text(x_pos, 0.23, use, ha=\"center\", fontsize=7, va=\"center\")\n",
    "\n",
    "# Bottom tips\n",
    "ax.text(0.5, 0.08, \"Key Tips:\", ha=\"center\", fontsize=10, fontweight=\"bold\")\n",
    "ax.text(\n",
    "    0.5,\n",
    "    0.04,\n",
    "    \"1. ALWAYS use clustered SEs  |  2. Hausman test: FE vs RE  |  3. CRE: flexible middle ground\",\n",
    "    ha=\"center\",\n",
    "    fontsize=8,\n",
    ")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "notebooks//ipynb,markdown//md,scripts//py"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
