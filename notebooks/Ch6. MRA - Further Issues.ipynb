{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 6: Multiple Regression Analysis - Further Issues\n",
    "\n",
    "Advanced applications of multiple regression require careful attention to model specification, functional form selection, and prediction methodology. This chapter extends foundational regression concepts to address practical challenges in empirical research: choosing appropriate transformations of variables, modeling interaction effects, incorporating quadratic relationships, and constructing prediction intervals that account for multiple sources of uncertainty.\n",
    "\n",
    "The development proceeds hierarchically from data scaling considerations to sophisticated modeling techniques. We examine how changes in measurement units affect coefficient interpretation (Section 6.1), introduce logarithmic transformations for modeling percentage effects and elasticities (Section 6.2), develop methods for incorporating quadratic and interaction terms (Section 6.3), address challenges in standardized coefficients and goodness-of-fit measures (Section 6.4), and conclude with prediction theory and interval construction (Section 6.5-6.6). Throughout, we implement these methods using Python's statsmodels library and illustrate applications with real datasets from econometric research."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-20T11:12:20.101164Z",
     "iopub.status.busy": "2025-10-20T11:12:20.101042Z",
     "iopub.status.idle": "2025-10-20T11:12:21.313737Z",
     "shell.execute_reply": "2025-10-20T11:12:21.313442Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.formula.api as smf\n",
    "import wooldridge as wool\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2475cd5b",
   "metadata": {},
   "source": [
    "## 6.1 Model Formulae\n",
    "\n",
    "This section explores how to use model formulae effectively to specify different types of regression models beyond the basic linear form. We will cover data scaling, standardization, the use of logarithms, quadratic and polynomial terms, and interaction effects. These techniques allow us to capture more complex relationships between variables and improve the fit and interpretability of our regression models.\n",
    "\n",
    "### 6.1.1 Data Scaling: Arithmetic Operations within a Formula\n",
    "\n",
    "Sometimes, the units in which variables are measured can affect the magnitude and interpretation of regression coefficients.  Scaling variables, such as dividing by a constant, can be useful for presenting coefficients in a more meaningful way.  `statsmodels` allows for arithmetic operations directly within the model formula, making it convenient to scale variables during model specification.\n",
    "\n",
    "Consider the following model investigating the determinants of birth weight:\n",
    "\n",
    "$$ \\text{bwght} = \\beta_0 + \\beta_1 \\cdot \\text{cigs} + \\beta_2 \\cdot \\text{faminc} + u$$\n",
    "\n",
    "where:\n",
    "- `bwght` is birth weight in ounces.\n",
    "- `cigs` is the average number of cigarettes smoked per day by the mother during pregnancy.\n",
    "- `faminc` is family income.\n",
    "\n",
    "We might want to express birth weight in pounds instead of ounces or cigarettes in packs per day instead of individual cigarettes. Let's see how this can be done and how it affects the coefficients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8afa48d3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-20T11:12:21.315312Z",
     "iopub.status.busy": "2025-10-20T11:12:21.315179Z",
     "iopub.status.idle": "2025-10-20T11:12:21.338175Z",
     "shell.execute_reply": "2025-10-20T11:12:21.337907Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>b</th>\n",
       "      <th>b_lbs</th>\n",
       "      <th>b_lbs2</th>\n",
       "      <th>b_packs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>I(cigs / 20)</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-9.2682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Intercept</th>\n",
       "      <td>116.9741</td>\n",
       "      <td>7.3109</td>\n",
       "      <td>7.3109</td>\n",
       "      <td>116.9741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cigs</th>\n",
       "      <td>-0.4634</td>\n",
       "      <td>-0.0290</td>\n",
       "      <td>-0.0290</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>faminc</th>\n",
       "      <td>0.0928</td>\n",
       "      <td>0.0058</td>\n",
       "      <td>0.0058</td>\n",
       "      <td>0.0928</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     b   b_lbs  b_lbs2   b_packs\n",
       "I(cigs / 20)       NaN     NaN     NaN   -9.2682\n",
       "Intercept     116.9741  7.3109  7.3109  116.9741\n",
       "cigs           -0.4634 -0.0290 -0.0290       NaN\n",
       "faminc          0.0928  0.0058  0.0058    0.0928"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bwght = wool.data(\"bwght\")\n",
    "\n",
    "# regress and report coefficients:\n",
    "reg = smf.ols(formula=\"bwght ~ cigs + faminc\", data=bwght)\n",
    "results = reg.fit()\n",
    "\n",
    "# weight in pounds, manual way:\n",
    "bwght[\"bwght_lbs\"] = bwght[\"bwght\"] / 16  # 1 pound = 16 ounces\n",
    "reg_lbs = smf.ols(formula=\"bwght_lbs ~ cigs + faminc\", data=bwght)\n",
    "results_lbs = reg_lbs.fit()\n",
    "\n",
    "# weight in pounds, direct way:\n",
    "reg_lbs2 = smf.ols(\n",
    "    formula=\"I(bwght/16) ~ cigs + faminc\",\n",
    "    data=bwght,\n",
    ")  # Use I() to perform arithmetic within formula\n",
    "results_lbs2 = reg_lbs2.fit()\n",
    "\n",
    "# packs of cigarettes:\n",
    "reg_packs = smf.ols(\n",
    "    formula=\"bwght ~ I(cigs/20) + faminc\",\n",
    "    data=bwght,\n",
    ")  # Assuming 20 cigarettes per pack\n",
    "results_packs = reg_packs.fit()\n",
    "\n",
    "# compare results:\n",
    "table = pd.DataFrame(\n",
    "    {\n",
    "        \"b\": round(results.params, 4),\n",
    "        \"b_lbs\": round(results_lbs.params, 4),\n",
    "        \"b_lbs2\": round(results_lbs2.params, 4),\n",
    "        \"b_packs\": round(results_packs.params, 4),\n",
    "    },\n",
    ")\n",
    "table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a33ff6cf",
   "metadata": {},
   "source": [
    "**Interpretation of Results:**\n",
    "\n",
    "- **`b` (bwght):** This column shows the coefficients when birth weight is in ounces and cigarettes are in individual units.  For example, the coefficient for `cigs` is approximately -0.4638, meaning that, holding family income constant, each additional cigarette smoked per day is associated with a decrease in birth weight of about 0.46 ounces.\n",
    "- **`b_lbs` and `b_lbs2` (bwght_lbs):** These columns show the coefficients when birth weight is converted to pounds. Notice that the coefficients for `b_lbs` (manual conversion) and `b_lbs2` (direct conversion in formula) are identical.  The coefficient for `cigs` is now approximately -0.0290. This is exactly the coefficient from the first regression divided by 16 (-0.4638 / 16 ~= -0.0290), as expected.  An additional cigarette is now associated with a decrease of about 0.029 pounds in birth weight.\n",
    "- **`b_packs` (packs of cigs):**  Here, cigarettes are converted to packs (assuming 20 cigarettes per pack) within the formula. The coefficient for `I(cigs/20)` is approximately -9.2762. This is 20 times the coefficient from the first regression (-0.4638 * 20 ~= -9.276), as expected. One additional pack of cigarettes smoked per day is associated with a decrease of about 9.27 ounces in birth weight.\n",
    "\n",
    "**Key takeaway:** Scaling the dependent or independent variables changes the scale of the corresponding regression coefficients but does not fundamentally alter the relationship being estimated.  It's crucial to be mindful of the units and choose scaling that makes the coefficients easily interpretable in the context of the problem. Using `I()` within the formula allows for convenient on-the-fly scaling.\n",
    "\n",
    "### 6.1.2 Standardization: Beta Coefficients\n",
    "\n",
    "Standardization involves transforming variables to have a mean of zero and a standard deviation of one.  This is particularly useful when comparing the relative effects of independent variables measured in different units.  The coefficients obtained from regressions with standardized variables are called *beta coefficients* or *standardized coefficients*. They represent the change in the dependent variable (in standard deviation units) for a one standard deviation change in the independent variable, holding other factors constant.\n",
    "\n",
    "The standardization formula for a variable $x$ is:\n",
    "\n",
    "$$z_x = \\frac{x - \\bar{x}}{\\text{sd}(x)}$$\n",
    "\n",
    "where $\\bar{x}$ is the sample mean and $\\text{sd}(x)$ is the sample standard deviation of $x$.\n",
    "\n",
    "Let's revisit the housing price example and standardize some of the variables to obtain beta coefficients.\n",
    "\n",
    "### Example 6.1: Effects of Pollution on Housing Prices (Standardized Variables)\n",
    "\n",
    "We consider a model to examine the effect of air pollution (`nox`, nitrogen oxide concentration) and other factors on housing prices (`price`). We'll standardize `price`, `nox`, `crime`, `rooms`, `dist` (distance to employment centers), and `stratio` (student-teacher ratio).\n",
    "\n",
    "$$\\text{price\\_sc} = \\beta_0 + \\beta_1 \\cdot \\text{nox\\_sc} + \\beta_2 \\cdot \\text{crime\\_sc} + \\beta_3 \\cdot \\text{rooms\\_sc} + \\beta_4 \\cdot \\text{dist\\_sc} + \\beta_5 \\cdot \\text{stratio\\_sc} + u$$\n",
    "\n",
    "where the `_sc` suffix denotes the standardized version of each variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3377231d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-20T11:12:21.339492Z",
     "iopub.status.busy": "2025-10-20T11:12:21.339394Z",
     "iopub.status.idle": "2025-10-20T11:12:21.354917Z",
     "shell.execute_reply": "2025-10-20T11:12:21.354674Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>b</th>\n",
       "      <th>se</th>\n",
       "      <th>t</th>\n",
       "      <th>pval</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>nox_sc</th>\n",
       "      <td>-0.3404</td>\n",
       "      <td>0.0445</td>\n",
       "      <td>-7.6511</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>crime_sc</th>\n",
       "      <td>-0.1433</td>\n",
       "      <td>0.0307</td>\n",
       "      <td>-4.6693</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rooms_sc</th>\n",
       "      <td>0.5139</td>\n",
       "      <td>0.0300</td>\n",
       "      <td>17.1295</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dist_sc</th>\n",
       "      <td>-0.2348</td>\n",
       "      <td>0.0430</td>\n",
       "      <td>-5.4641</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stratio_sc</th>\n",
       "      <td>-0.2703</td>\n",
       "      <td>0.0299</td>\n",
       "      <td>-9.0274</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 b      se        t  pval\n",
       "nox_sc     -0.3404  0.0445  -7.6511   0.0\n",
       "crime_sc   -0.1433  0.0307  -4.6693   0.0\n",
       "rooms_sc    0.5139  0.0300  17.1295   0.0\n",
       "dist_sc    -0.2348  0.0430  -5.4641   0.0\n",
       "stratio_sc -0.2703  0.0299  -9.0274   0.0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define a function for the standardization:\n",
    "def scale(x):\n",
    "    x_mean = np.mean(x)\n",
    "    x_var = np.var(x, ddof=1)  # ddof=1 for sample standard deviation (denominator n-1)\n",
    "    x_scaled = (x - x_mean) / np.sqrt(x_var)\n",
    "    return x_scaled\n",
    "\n",
    "\n",
    "# standardize and estimate:\n",
    "hprice2 = wool.data(\"hprice2\")\n",
    "hprice2[\"price_sc\"] = scale(hprice2[\"price\"])\n",
    "hprice2[\"nox_sc\"] = scale(hprice2[\"nox\"])\n",
    "hprice2[\"crime_sc\"] = scale(hprice2[\"crime\"])\n",
    "hprice2[\"rooms_sc\"] = scale(hprice2[\"rooms\"])\n",
    "hprice2[\"dist_sc\"] = scale(hprice2[\"dist\"])\n",
    "hprice2[\"stratio_sc\"] = scale(hprice2[\"stratio\"])\n",
    "\n",
    "reg = smf.ols(\n",
    "    formula=\"price_sc ~ 0 + nox_sc + crime_sc + rooms_sc + dist_sc + stratio_sc\",  # No constant needed after standardization if all variables are standardized\n",
    "    data=hprice2,\n",
    ")\n",
    "results = reg.fit()\n",
    "\n",
    "# print regression table:\n",
    "table = pd.DataFrame(\n",
    "    {\n",
    "        \"b\": round(results.params, 4),\n",
    "        \"se\": round(results.bse, 4),\n",
    "        \"t\": round(results.tvalues, 4),\n",
    "        \"pval\": round(results.pvalues, 4),\n",
    "    },\n",
    ")\n",
    "table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Interpretation of Beta Coefficients:**\n",
    "\n",
    "- **`nox_sc` coefficient (-0.3404):**  A one standard deviation increase in nitrogen oxide concentration (`nox`) is associated with a decrease of 0.3404 standard deviations in housing price, holding other standardized variables constant.\n",
    "- **`rooms_sc` coefficient (0.5139):** A one standard deviation increase in the number of rooms (`rooms`) is associated with an increase of 0.5139 standard deviations in housing price, holding other standardized variables constant.\n",
    "\n",
    "**Comparing Effects:**\n",
    "\n",
    "By comparing the absolute values of the beta coefficients, we can get a sense of the relative importance of each independent variable in explaining the variation in the dependent variable. In this example, `rooms_sc` has the largest beta coefficient (in absolute value), suggesting that the number of rooms has the strongest relative effect on housing price among the variables considered in the standardized model.  However, remember that \"importance\" here is in terms of explaining variance, not necessarily causal importance.\n",
    "\n",
    "**Note on Constant Term:** When all variables (dependent and independent) are standardized and a constant is included in the regression, the constant will always be zero.  Therefore, it's common practice to suppress the constant term (by using `formula=\"price_sc ~ 0 + ...\"` or `formula=\"price_sc ~ -1 + ...\"`) when working with standardized variables, as done in the example above.\n",
    "\n",
    "### 6.1.3 Logarithms\n",
    "\n",
    "Logarithmic transformations are frequently used in regression analysis for several reasons:\n",
    "\n",
    "1. **Nonlinearity:** Log transformations can linearize relationships that are nonlinear in levels.\n",
    "2. **Heteroskedasticity:** They can help reduce heteroskedasticity in the error term.\n",
    "3. **Interpretation:** Coefficients in log-transformed models often have convenient percentage change interpretations.\n",
    "\n",
    "Common log transformations include:\n",
    "\n",
    "- **Log-level model:**  $\\log(y) = \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + u$.  Here, a one-unit change in $x_1$ is associated with approximately a $100 \\cdot \\beta_1$ percent change in $y$. This approximation is accurate when $|\\beta_1|$ is small (typically $|\\beta_1| < 0.1$); the exact percentage change is $100 \\cdot [\\exp(\\beta_1) - 1]$ percent.\n",
    "- **Level-log model:** $y = \\beta_0 + \\beta_1 \\log(x_1) + \\beta_2 x_2 + u$.  Here, a 1% increase in $x_1$ is associated with approximately a $\\beta_1 / 100$ unit change in $y$. More precisely, the change in $y$ from increasing $x_1$ by factor $c$ (e.g., $c=1.01$ for 1%) is $\\beta_1 \\cdot \\log(c)$.\n",
    "- **Log-log model:** $\\log(y) = \\beta_0 + \\beta_1 \\log(x_1) + \\beta_2 \\log(x_2) + u$. Here, a 1% change in $x_1$ is associated with a $\\beta_1$ percent change in $y$. The coefficient $\\beta_1$ is the **elasticity** of $y$ with respect to $x_1$, and this interpretation is exact, not an approximation.\n",
    "\n",
    "Let's consider a log-log model for housing prices:\n",
    "\n",
    "$$\\log(\\text{price}) = \\beta_0 + \\beta_1 \\log(\\text{nox}) + \\beta_2 \\text{rooms} + u$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-20T11:12:21.356314Z",
     "iopub.status.busy": "2025-10-20T11:12:21.356230Z",
     "iopub.status.idle": "2025-10-20T11:12:21.366693Z",
     "shell.execute_reply": "2025-10-20T11:12:21.366436Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>b</th>\n",
       "      <th>se</th>\n",
       "      <th>t</th>\n",
       "      <th>pval</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Intercept</th>\n",
       "      <td>9.2337</td>\n",
       "      <td>0.1877</td>\n",
       "      <td>49.1835</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>np.log(nox)</th>\n",
       "      <td>-0.7177</td>\n",
       "      <td>0.0663</td>\n",
       "      <td>-10.8182</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rooms</th>\n",
       "      <td>0.3059</td>\n",
       "      <td>0.0190</td>\n",
       "      <td>16.0863</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  b      se        t  pval\n",
       "Intercept    9.2337  0.1877  49.1835   0.0\n",
       "np.log(nox) -0.7177  0.0663 -10.8182   0.0\n",
       "rooms        0.3059  0.0190  16.0863   0.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hprice2 = wool.data(\"hprice2\")\n",
    "\n",
    "reg = smf.ols(formula=\"np.log(price) ~ np.log(nox) + rooms\", data=hprice2)\n",
    "results = reg.fit()\n",
    "\n",
    "# print regression table:\n",
    "table = pd.DataFrame(\n",
    "    {\n",
    "        \"b\": round(results.params, 4),\n",
    "        \"se\": round(results.bse, 4),\n",
    "        \"t\": round(results.tvalues, 4),\n",
    "        \"pval\": round(results.pvalues, 4),\n",
    "    },\n",
    ")\n",
    "table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Interpretation of Log-Log Model Coefficients:**\n",
    "\n",
    "- **`np.log(nox)` coefficient (-0.7177):**  A 1% increase in nitrogen oxide concentration (`nox`) is associated with approximately a 0.7177% decrease in housing price, holding the number of rooms constant.  This is interpreted as an elasticity: the elasticity of housing price with respect to `nox` is approximately -0.72.\n",
    "- **`rooms` coefficient (0.3059):**  An increase of one room is associated with approximately a $100 \\cdot 0.3059 \\% = 30.59 \\%$ increase in housing price, holding `nox` constant. This is interpreted using the log-level approximation.\n",
    "\n",
    "**When to use Log Transformations:**\n",
    "\n",
    "- Consider using log transformations for variables that are positively skewed.\n",
    "- If you suspect percentage changes are more relevant than absolute changes in the relationship.\n",
    "- When dealing with variables that must be non-negative (like prices, income, quantities).\n",
    "- Log-log models are particularly useful for estimating elasticities.\n",
    "\n",
    "### 6.1.4 Quadratics and Polynomials\n",
    "\n",
    "To model nonlinear relationships, we can include quadratic, cubic, or higher-order polynomial terms of independent variables in the regression model.  A quadratic regression model includes the square of an independent variable:\n",
    "\n",
    "$$ y = \\beta_0 + \\beta_1 x + \\beta_2 x^2 + u$$\n",
    "\n",
    "This allows for a U-shaped or inverted U-shaped relationship between $y$ and $x$. The slope of the relationship between $y$ and $x$ is no longer constant but depends on the value of $x$:\n",
    "\n",
    "$$ \\frac{\\partial y}{\\partial x} = \\beta_1 + 2\\beta_2 x $$\n",
    "\n",
    "To find the turning point (minimum or maximum) of the quadratic relationship, we can set the derivative to zero and solve for $x$:\n",
    "\n",
    "$$ \\beta_1 + 2\\beta_2 x = 0 \\implies x = -\\frac{\\beta_1}{2\\beta_2} $$\n",
    "\n",
    "### Example 6.2: Effects of Pollution on Housing Prices with Quadratic Terms\n",
    "\n",
    "Let's extend our housing price model to include a quadratic term for `rooms` and `dist` to allow for potentially nonlinear effects:\n",
    "\n",
    "$$\\log(\\text{price}) = \\beta_0 + \\beta_1 \\log(\\text{nox}) + \\beta_2 \\log(\\text{dist}) + \\beta_3 \\text{rooms} + \\beta_4 \\text{rooms}^2 + \\beta_5 \\text{stratio} + u$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-20T11:12:21.367959Z",
     "iopub.status.busy": "2025-10-20T11:12:21.367874Z",
     "iopub.status.idle": "2025-10-20T11:12:21.415468Z",
     "shell.execute_reply": "2025-10-20T11:12:21.415165Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>R-squared</td>\n",
       "      <td>0.6028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Number of observations</td>\n",
       "      <td>506</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Metric   Value\n",
       "0               R-squared  0.6028\n",
       "1  Number of observations     506"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load housing price data for quadratic specification\n",
    "hprice2 = wool.data(\"hprice2\")\n",
    "\n",
    "# Dataset information\n",
    "pd.DataFrame(\n",
    "    {\n",
    "        \"Metric\": [\"Number of observations\", \"Number of variables\"],\n",
    "        \"Value\": [hprice2.shape[0], hprice2.shape[1]],\n",
    "    },\n",
    ")\n",
    "\n",
    "# Room statistics\n",
    "pd.DataFrame(\n",
    "    {\n",
    "        \"Statistic\": [\"Mean\", \"Min\", \"Max\"],\n",
    "        \"Value\": [\n",
    "            f\"{hprice2['rooms'].mean():.2f}\",\n",
    "            hprice2[\"rooms\"].min(),\n",
    "            hprice2[\"rooms\"].max(),\n",
    "        ],\n",
    "    },\n",
    ")\n",
    "\n",
    "# Specify quadratic model to capture nonlinear effects\n",
    "# I() protects arithmetic operations in formula notation\n",
    "quadratic_model = smf.ols(\n",
    "    formula=\"np.log(price) ~ np.log(nox) + np.log(dist) + rooms + I(rooms**2) + stratio\",\n",
    "    data=hprice2,\n",
    ")\n",
    "quadratic_results = quadratic_model.fit()\n",
    "\n",
    "# Display results with enhanced formatting\n",
    "coefficients_table = pd.DataFrame(\n",
    "    {\n",
    "        \"Coefficient\": quadratic_results.params.round(4),\n",
    "        \"Std_Error\": quadratic_results.bse.round(4),\n",
    "        \"t_statistic\": quadratic_results.tvalues.round(4),\n",
    "        \"p_value\": quadratic_results.pvalues.round(4),\n",
    "        \"Sig\": [\n",
    "            \"***\" if p < 0.01 else \"**\" if p < 0.05 else \"*\" if p < 0.1 else \"\"\n",
    "            for p in quadratic_results.pvalues\n",
    "        ],\n",
    "    },\n",
    ")\n",
    "\n",
    "# QUADRATIC MODEL RESULTS\n",
    "# Dependent Variable: log(price)\n",
    "coefficients_table\n",
    "# Model statistics\n",
    "pd.DataFrame(\n",
    "    {\n",
    "        \"Metric\": [\"R-squared\", \"Number of observations\"],\n",
    "        \"Value\": [f\"{quadratic_results.rsquared:.4f}\", int(quadratic_results.nobs)],\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Interpretation of Quadratic Term:**\n",
    "\n",
    "- **`rooms` coefficient (-0.5451) and `I(rooms**2)` coefficient (0.0623):** The negative coefficient on `rooms` and the positive coefficient on `rooms**2` suggest a U-shaped relationship between `rooms` and $\\log(\\text{price})$.  Initially, as the number of rooms increases, housing price decreases at a decreasing rate. However, beyond a certain point, further increases in rooms lead to increases in price.\n",
    "\n",
    "**Precise Calculations for Quadratic Effects:**\n",
    "- Turning point: $\\text{rooms}^* = -(-0.5451)/(2 \\times 0.0623) = 4.38$ rooms\n",
    "- Marginal effect at mean (6.28 rooms): $-0.5451 + 2(0.0623)(6.28) = 0.237$ log points per room\n",
    "- Since dependent variable is log(price), a one-room increase at the mean raises price by approximately 23.7%\n",
    "- Units: The coefficients have units of (log dollars)/(room) and (log dollars)/(room^2)\n",
    "\n",
    "**Finding the Turning Point for Rooms:**\n",
    "\n",
    "The turning point (in terms of `rooms`) can be calculated as:\n",
    "\n",
    "$$ \\text{rooms} = -\\frac{\\beta_{\\text{rooms}}}{2\\beta_{\\text{rooms}^2}} = -\\frac{-0.5451}{2 \\cdot 0.0623} \\approx 4.38 $$\n",
    "\n",
    "This suggests that the relationship between `rooms` and $\\log(\\text{price})$ reaches its maximum (within the range of rooms considered in the model) at approximately 4.38 rooms.  It's important to examine the data range to see if this turning point is within the realistic range of the independent variable.\n",
    "\n",
    "**Polynomials beyond Quadratics:** Cubic or higher-order polynomials can be used to model even more complex nonlinearities, but they can also become harder to interpret and may lead to overfitting if too many terms are included without strong theoretical justification.\n",
    "\n",
    "### 6.1.5 Hypothesis Testing with Nonlinear Terms\n",
    "\n",
    "When we include nonlinear terms like quadratics or interactions, we often want to test hypotheses about the joint significance of these terms. For example, in the quadratic model above, we might want to test whether the quadratic term for `rooms` is jointly significant with the linear term for `rooms`.  We can use the F-test for joint hypotheses in `statsmodels` to do this.\n",
    "\n",
    "Let's test the joint hypothesis that both the coefficient on `rooms` and the coefficient on `rooms**2` are simultaneously zero in Example 6.2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-20T11:12:21.416713Z",
     "iopub.status.busy": "2025-10-20T11:12:21.416629Z",
     "iopub.status.idle": "2025-10-20T11:12:21.428533Z",
     "shell.execute_reply": "2025-10-20T11:12:21.428270Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>F-statistic</td>\n",
       "      <td>110.4188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>p-value</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Metric     Value\n",
       "0  F-statistic  110.4188\n",
       "1      p-value    0.0000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hprice2 = wool.data(\"hprice2\")\n",
    "n = hprice2.shape[0]\n",
    "\n",
    "reg = smf.ols(\n",
    "    formula=\"np.log(price) ~ np.log(nox)+np.log(dist)+rooms+I(rooms**2)+stratio\",\n",
    "    data=hprice2,\n",
    ")\n",
    "results = reg.fit()\n",
    "\n",
    "# implemented F test for rooms:\n",
    "hypotheses = [\n",
    "    \"rooms = 0\",\n",
    "    \"I(rooms ** 2) = 0\",\n",
    "]  # Define the null hypotheses for joint test\n",
    "ftest = results.f_test(hypotheses)  # Perform the F-test\n",
    "fstat = ftest.statistic\n",
    "fpval = ftest.pvalue\n",
    "\n",
    "# F-test results\n",
    "pd.DataFrame(\n",
    "    {\n",
    "        \"Metric\": [\"F-statistic\", \"p-value\"],\n",
    "        \"Value\": [f\"{fstat:.4f}\", f\"{fpval:.4f}\"],\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Interpretation of F-test:**\n",
    "\n",
    "The F-statistic is 110.42, and the p-value is very close to zero.  Since the p-value is much smaller than conventional significance levels (e.g., 0.05 or 0.01), we reject the null hypothesis that both coefficients on `rooms` and `rooms**2` are jointly zero.  We conclude that the number of rooms, considering both its linear and quadratic terms, is jointly statistically significant in explaining housing prices in this model.\n",
    "\n",
    "### 6.1.6 Interaction Terms\n",
    "\n",
    "Interaction terms allow the effect of one independent variable on the dependent variable to depend on the level of another independent variable.  A basic interaction model with two independent variables $x_1$ and $x_2$ includes their product term:\n",
    "\n",
    "$$ y = \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + \\beta_3 x_1 x_2 + u$$\n",
    "\n",
    "In this model:\n",
    "- $\\beta_1$ is the partial effect of $x_1$ on $y$ when $x_2 = 0$.\n",
    "- $\\beta_2$ is the partial effect of $x_2$ on $y$ when $x_1 = 0$.\n",
    "- $\\beta_3$ captures the *interaction effect*. It tells us how the effect of $x_1$ on $y$ changes as $x_2$ changes (and vice versa).\n",
    "\n",
    "The partial effect of $x_1$ on $y$ is given by:\n",
    "\n",
    "$$ \\frac{\\partial y}{\\partial x_1} = \\beta_1 + \\beta_3 x_2 $$\n",
    "\n",
    "Similarly, the partial effect of $x_2$ on $y$ is:\n",
    "\n",
    "$$ \\frac{\\partial y}{\\partial x_2} = \\beta_2 + \\beta_3 x_1 $$\n",
    "\n",
    "### Example 6.3: Effects of Attendance on Final Exam Performance with Interaction\n",
    "\n",
    "Consider a model where we want to see how attendance rate (`atndrte`) and prior GPA (`priGPA`) affect student performance on a standardized final exam (`stndfnl`). We might hypothesize that the effect of attendance on exam performance is stronger for students with higher prior GPAs.  To test this, we can include an interaction term between `atndrte` and `priGPA`. We also include quadratic terms for `priGPA` and `ACT` score to account for potential nonlinear effects of these control variables.\n",
    "\n",
    "$$\\text{stndfnl} = \\beta_0 + \\beta_1 \\text{atndrte} + \\beta_2 \\text{priGPA} + \\beta_3 \\text{ACT} + \\beta_4 \\text{priGPA}^2 + \\beta_5 \\text{ACT}^2 + \\beta_6 \\text{atndrte} \\cdot \\text{priGPA} + u$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-20T11:12:21.429766Z",
     "iopub.status.busy": "2025-10-20T11:12:21.429682Z",
     "iopub.status.idle": "2025-10-20T11:12:21.441896Z",
     "shell.execute_reply": "2025-10-20T11:12:21.441616Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>R-squared</td>\n",
       "      <td>0.2287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Adjusted R-squared</td>\n",
       "      <td>0.2218</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Metric   Value\n",
       "0           R-squared  0.2287\n",
       "1  Adjusted R-squared  0.2218"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load student attendance data\n",
    "attend = wool.data(\"attend\")\n",
    "n = attend.shape[0]\n",
    "\n",
    "# Examine key variables\n",
    "# Dataset information\n",
    "pd.DataFrame(\n",
    "    {\n",
    "        \"Metric\": [\"Number of observations\"],\n",
    "        \"Value\": [n],\n",
    "    },\n",
    ")\n",
    "\n",
    "# Summary statistics\n",
    "summary_stats = pd.DataFrame(\n",
    "    {\n",
    "        \"Variable\": [\"Attendance rate\", \"Prior GPA\"],\n",
    "        \"Mean\": [f\"{attend['atndrte'].mean():.1f}%\", f\"{attend['priGPA'].mean():.2f}\"],\n",
    "        \"Std Dev\": [f\"{attend['atndrte'].std():.1f}%\", f\"{attend['priGPA'].std():.2f}\"],\n",
    "    },\n",
    ")\n",
    "summary_stats\n",
    "\n",
    "# Specify model with interaction and quadratic terms\n",
    "# atndrte*priGPA creates main effects + interaction automatically\n",
    "interaction_model = smf.ols(\n",
    "    formula=\"stndfnl ~ atndrte*priGPA + ACT + I(priGPA**2) + I(ACT**2)\",\n",
    "    data=attend,\n",
    ")\n",
    "interaction_results = interaction_model.fit()\n",
    "\n",
    "# Create comprehensive results table\n",
    "results_table = pd.DataFrame(\n",
    "    {\n",
    "        \"Coefficient\": interaction_results.params.round(4),\n",
    "        \"Std_Error\": interaction_results.bse.round(4),\n",
    "        \"t_statistic\": interaction_results.tvalues.round(4),\n",
    "        \"p_value\": interaction_results.pvalues.round(4),\n",
    "        \"Variable_Type\": [\n",
    "            \"Intercept\",\n",
    "            \"Main Effect\",  # atndrte\n",
    "            \"Main Effect\",  # priGPA\n",
    "            \"Control\",  # ACT\n",
    "            \"Quadratic\",  # priGPA^2\n",
    "            \"Quadratic\",  # ACT^2\n",
    "            \"Interaction\",  # atndrtexpriGPA\n",
    "        ],\n",
    "    },\n",
    ")\n",
    "\n",
    "# INTERACTION MODEL RESULTS\n",
    "# Dependent Variable: stndfnl (Standardized Final Exam Score)\n",
    "results_table\n",
    "# Model statistics with interaction\n",
    "pd.DataFrame(\n",
    "    {\n",
    "        \"Metric\": [\"R-squared\", \"Adjusted R-squared\"],\n",
    "        \"Value\": [\n",
    "            f\"{interaction_results.rsquared:.4f}\",\n",
    "            f\"{interaction_results.rsquared_adj:.4f}\",\n",
    "        ],\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77408459",
   "metadata": {},
   "source": [
    "**Interpretation of Interaction Term:**\n",
    "\n",
    "- **`atndrte:priGPA` coefficient (0.0101):** This positive coefficient suggests that the effect of attendance rate on final exam score increases as prior GPA increases.  In other words, attendance seems to be more beneficial for students with higher prior GPAs.\n",
    "\n",
    "**Calculating Partial Effect of Attendance at a Specific `priGPA`:**\n",
    "\n",
    "Let's calculate the estimated partial effect of attendance rate on `stndfnl` for a student with a prior GPA of 2.59 (the sample average of `priGPA`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-20T11:12:21.443115Z",
     "iopub.status.busy": "2025-10-20T11:12:21.443026Z",
     "iopub.status.idle": "2025-10-20T11:12:21.447354Z",
     "shell.execute_reply": "2025-10-20T11:12:21.447139Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GPA Level</th>\n",
       "      <th>Partial Effect of Attendance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>At mean GPA (2.59)</td>\n",
       "      <td>0.0077</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            GPA Level Partial Effect of Attendance\n",
       "0  At mean GPA (2.59)                       0.0077"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate partial effect of attendance at specific GPA values\n",
    "# dstndfnl/datndrte = beta_1 + beta_6*priGPA\n",
    "\n",
    "# Extract coefficients\n",
    "coefficients = interaction_results.params\n",
    "mean_priGPA = attend[\"priGPA\"].mean()  # Sample average GPA\n",
    "\n",
    "# Calculate partial effect at mean GPA\n",
    "partial_effect_at_mean = (\n",
    "    coefficients[\"atndrte\"] + mean_priGPA * coefficients[\"atndrte:priGPA\"]\n",
    ")\n",
    "\n",
    "# PARTIAL EFFECT ANALYSIS\n",
    "# Partial effect calculation\n",
    "pd.DataFrame(\n",
    "    {\n",
    "        \"Component\": [\n",
    "            \"Base effect of attendance\",\n",
    "            \"Interaction at mean GPA\",\n",
    "            \"Total partial effect\",\n",
    "        ],\n",
    "        \"Value\": [\n",
    "            f\"{coefficients['atndrte']:.4f}\",\n",
    "            f\"{mean_priGPA:.2f} x {coefficients['atndrte:priGPA']:.4f}\",\n",
    "            f\"{partial_effect_at_mean:.4f}\",\n",
    "        ],\n",
    "    },\n",
    ")\n",
    "pd.DataFrame(\n",
    "    {\n",
    "        \"GPA Level\": [f\"At mean GPA ({mean_priGPA:.2f})\"],\n",
    "        \"Partial Effect of Attendance\": [f\"{partial_effect_at_mean:.4f}\"],\n",
    "    },\n",
    ")\n",
    "# \\nInterpretation: For a student with average prior GPA,\n",
    "# Interpretation: a 1 percentage point increase in attendance rate is associated\n",
    "# with a change in standardized exam score shown above."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9abb2339",
   "metadata": {},
   "source": [
    "The estimated partial effect of attendance at `priGPA = 2.59` is approximately 0.466. This means that for a student with an average prior GPA, a one percentage point increase in attendance rate is associated with an increase of about 0.466 points in the standardized final exam score.\n",
    "\n",
    "**Testing Significance of Partial Effect at a Specific `priGPA`:**\n",
    "\n",
    "We can also test whether this partial effect is statistically significant at a specific value of `priGPA`.  We can formulate a hypothesis test for this. For example, to test if the partial effect of attendance is zero when `priGPA = 2.59`, we test:\n",
    "\n",
    "$$ H_0: \\beta_{\\text{atndrte}} + 2.59 \\cdot \\beta_{\\text{atndrte} \\cdot \\text{priGPA}} = 0 $$\n",
    "\n",
    "We can use the `f_test` method in `statsmodels` to perform this test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-20T11:12:21.448609Z",
     "iopub.status.busy": "2025-10-20T11:12:21.448526Z",
     "iopub.status.idle": "2025-10-20T11:12:21.452726Z",
     "shell.execute_reply": "2025-10-20T11:12:21.452475Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>F-statistic</td>\n",
       "      <td>8.6326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>p-value</td>\n",
       "      <td>0.0034</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Metric   Value\n",
       "0  F-statistic  8.6326\n",
       "1      p-value  0.0034"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# F test for partial effect at priGPA=2.59:\n",
    "# We need to create the linear combination manually\n",
    "# Partial effect = beta_atndrte + 2.59 * beta_interaction\n",
    "R = np.zeros((1, len(interaction_results.params)))\n",
    "R[0, interaction_results.params.index.get_loc(\"atndrte\")] = 1\n",
    "R[0, interaction_results.params.index.get_loc(\"atndrte:priGPA\")] = 2.59\n",
    "ftest = interaction_results.f_test(R)\n",
    "fstat = ftest.statistic\n",
    "fpval = ftest.pvalue\n",
    "\n",
    "# F-test results\n",
    "pd.DataFrame(\n",
    "    {\n",
    "        \"Metric\": [\"F-statistic\", \"p-value\"],\n",
    "        \"Value\": [f\"{fstat:.4f}\", f\"{fpval:.4f}\"],\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Interpretation of Test:**\n",
    "\n",
    "The p-value for this test is approximately 0.0496, which is less than 0.05.  Therefore, at the 5% significance level, we reject the null hypothesis. We conclude that the partial effect of attendance rate on standardized final exam score is statistically significantly different from zero for students with a prior GPA of 2.59.\n",
    "\n",
    "## 6.2 Prediction\n",
    "\n",
    "Regression models are not only used for estimating relationships between variables but also for prediction.  Given values for the independent variables, we can use the estimated regression equation to predict the value of the dependent variable.  This section covers point predictions, confidence intervals for the mean prediction, and prediction intervals for individual outcomes.\n",
    "\n",
    "### 6.2.1 Confidence and Prediction Intervals for Predictions\n",
    "\n",
    "When we make a prediction using a regression model, there are two sources of uncertainty:\n",
    "\n",
    "1. **Uncertainty about the population regression function:**  This is reflected in the standard errors of the regression coefficients and leads to uncertainty about the *average* value of $y$ for given values of $x$. This is quantified by the **confidence interval for the mean prediction**.\n",
    "2. **Uncertainty about the individual error term:** Even if we knew the true population regression function perfectly, an individual outcome $y$ will deviate from the mean prediction due to the random error term $u$. This adds additional uncertainty when predicting an *individual* value of $y$. This is quantified by the **prediction interval**.\n",
    "\n",
    "The confidence interval for the mean prediction is always narrower than the prediction interval because the prediction interval accounts for both sources of uncertainty, while the confidence interval only accounts for the first source.\n",
    "\n",
    "Let's use the college GPA example to illustrate prediction and interval estimation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-20T11:12:21.453815Z",
     "iopub.status.busy": "2025-10-20T11:12:21.453739Z",
     "iopub.status.idle": "2025-10-20T11:12:21.473056Z",
     "shell.execute_reply": "2025-10-20T11:12:21.472780Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>b</th>\n",
       "      <th>se</th>\n",
       "      <th>t</th>\n",
       "      <th>pval</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Intercept</th>\n",
       "      <td>1.4927</td>\n",
       "      <td>0.0753</td>\n",
       "      <td>19.8118</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sat</th>\n",
       "      <td>0.0015</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>22.8864</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hsperc</th>\n",
       "      <td>-0.0139</td>\n",
       "      <td>0.0006</td>\n",
       "      <td>-24.6981</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hsize</th>\n",
       "      <td>-0.0609</td>\n",
       "      <td>0.0165</td>\n",
       "      <td>-3.6895</td>\n",
       "      <td>0.0002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I(hsize ** 2)</th>\n",
       "      <td>0.0055</td>\n",
       "      <td>0.0023</td>\n",
       "      <td>2.4056</td>\n",
       "      <td>0.0162</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    b      se        t    pval\n",
       "Intercept      1.4927  0.0753  19.8118  0.0000\n",
       "sat            0.0015  0.0001  22.8864  0.0000\n",
       "hsperc        -0.0139  0.0006 -24.6981  0.0000\n",
       "hsize         -0.0609  0.0165  -3.6895  0.0002\n",
       "I(hsize ** 2)  0.0055  0.0023   2.4056  0.0162"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpa2 = wool.data(\"gpa2\")\n",
    "\n",
    "reg = smf.ols(formula=\"colgpa ~ sat + hsperc + hsize + I(hsize**2)\", data=gpa2)\n",
    "results = reg.fit()\n",
    "\n",
    "# print regression table:\n",
    "table = pd.DataFrame(\n",
    "    {\n",
    "        \"b\": round(results.params, 4),\n",
    "        \"se\": round(results.bse, 4),\n",
    "        \"t\": round(results.tvalues, 4),\n",
    "        \"pval\": round(results.pvalues, 4),\n",
    "    },\n",
    ")\n",
    "table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3046d78f",
   "metadata": {},
   "source": [
    "Suppose we want to predict the college GPA (`colgpa`) for a new student with the following characteristics: SAT score (`sat`) = 1200, high school percentile (`hsperc`) = 30, and high school size (`hsize`) = 5 (in hundreds). First, we create a Pandas DataFrame with these values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-20T11:12:21.474565Z",
     "iopub.status.busy": "2025-10-20T11:12:21.474477Z",
     "iopub.status.idle": "2025-10-20T11:12:21.478098Z",
     "shell.execute_reply": "2025-10-20T11:12:21.477662Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sat</th>\n",
       "      <th>hsperc</th>\n",
       "      <th>hsize</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>newPerson1</th>\n",
       "      <td>1200</td>\n",
       "      <td>30</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             sat  hsperc  hsize\n",
       "newPerson1  1200      30      5"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# generate data set containing the regressor values for predictions:\n",
    "cvalues1 = pd.DataFrame(\n",
    "    {\"sat\": [1200], \"hsperc\": [30], \"hsize\": [5]},\n",
    "    index=[\"newPerson1\"],\n",
    ")\n",
    "# Prediction for Caitlin\n",
    "cvalues1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d24c31a",
   "metadata": {},
   "source": [
    "To get the point prediction, we use the `predict()` method of the regression results object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-20T11:12:21.479463Z",
     "iopub.status.busy": "2025-10-20T11:12:21.479369Z",
     "iopub.status.idle": "2025-10-20T11:12:21.483832Z",
     "shell.execute_reply": "2025-10-20T11:12:21.483591Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "newPerson1    2.700075\n",
       "dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# point estimate of prediction (cvalues1):\n",
    "colgpa_pred1 = results.predict(cvalues1)\n",
    "# Predicted colGPA for Caitlin\n",
    "colgpa_pred1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "753858c9",
   "metadata": {},
   "source": [
    "The point prediction for college GPA for this student is approximately 2.70.\n",
    "\n",
    "We can predict for multiple new individuals at once by providing a DataFrame with multiple rows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-20T11:12:21.484974Z",
     "iopub.status.busy": "2025-10-20T11:12:21.484893Z",
     "iopub.status.idle": "2025-10-20T11:12:21.488083Z",
     "shell.execute_reply": "2025-10-20T11:12:21.487840Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sat</th>\n",
       "      <th>hsperc</th>\n",
       "      <th>hsize</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>newPerson1</th>\n",
       "      <td>1200</td>\n",
       "      <td>30</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>newPerson2</th>\n",
       "      <td>900</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>newPerson3</th>\n",
       "      <td>1400</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             sat  hsperc  hsize\n",
       "newPerson1  1200      30      5\n",
       "newPerson2   900      20      3\n",
       "newPerson3  1400       5      1"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define three sets of regressor variables:\n",
    "cvalues2 = pd.DataFrame(\n",
    "    {\"sat\": [1200, 900, 1400], \"hsperc\": [30, 20, 5], \"hsize\": [5, 3, 1]},\n",
    "    index=[\"newPerson1\", \"newPerson2\", \"newPerson3\"],\n",
    ")\n",
    "# Prediction for Jeff\n",
    "cvalues2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-20T11:12:21.489178Z",
     "iopub.status.busy": "2025-10-20T11:12:21.489103Z",
     "iopub.status.idle": "2025-10-20T11:12:21.493489Z",
     "shell.execute_reply": "2025-10-20T11:12:21.493236Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "newPerson1    2.700075\n",
       "newPerson2    2.425282\n",
       "newPerson3    3.457448\n",
       "dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# point estimate of prediction (cvalues2):\n",
    "colgpa_pred2 = results.predict(cvalues2)\n",
    "# Predicted colGPA for Jeff\n",
    "colgpa_pred2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 6.5: Confidence Interval for Predicted College GPA\n",
    "\n",
    "To obtain confidence and prediction intervals, we use the `get_prediction()` method followed by `summary_frame()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-20T11:12:21.494699Z",
     "iopub.status.busy": "2025-10-20T11:12:21.494624Z",
     "iopub.status.idle": "2025-10-20T11:12:21.514397Z",
     "shell.execute_reply": "2025-10-20T11:12:21.514136Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>mean_se</th>\n",
       "      <th>mean_ci_lower</th>\n",
       "      <th>mean_ci_upper</th>\n",
       "      <th>obs_ci_lower</th>\n",
       "      <th>obs_ci_upper</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.700075</td>\n",
       "      <td>0.019878</td>\n",
       "      <td>2.661104</td>\n",
       "      <td>2.739047</td>\n",
       "      <td>1.601749</td>\n",
       "      <td>3.798402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.425282</td>\n",
       "      <td>0.014258</td>\n",
       "      <td>2.397329</td>\n",
       "      <td>2.453235</td>\n",
       "      <td>1.327292</td>\n",
       "      <td>3.523273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.457448</td>\n",
       "      <td>0.027891</td>\n",
       "      <td>3.402766</td>\n",
       "      <td>3.512130</td>\n",
       "      <td>2.358452</td>\n",
       "      <td>4.556444</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       mean   mean_se  mean_ci_lower  mean_ci_upper  obs_ci_lower  \\\n",
       "0  2.700075  0.019878       2.661104       2.739047      1.601749   \n",
       "1  2.425282  0.014258       2.397329       2.453235      1.327292   \n",
       "2  3.457448  0.027891       3.402766       3.512130      2.358452   \n",
       "\n",
       "   obs_ci_upper  \n",
       "0      3.798402  \n",
       "1      3.523273  \n",
       "2      4.556444  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpa2 = wool.data(\"gpa2\")\n",
    "\n",
    "reg = smf.ols(formula=\"colgpa ~ sat + hsperc + hsize + I(hsize**2)\", data=gpa2)\n",
    "results = reg.fit()\n",
    "\n",
    "# define three sets of regressor variables:\n",
    "cvalues2 = pd.DataFrame(\n",
    "    {\"sat\": [1200, 900, 1400], \"hsperc\": [30, 20, 5], \"hsize\": [5, 3, 1]},\n",
    "    index=[\"newPerson1\", \"newPerson2\", \"newPerson3\"],\n",
    ")\n",
    "\n",
    "# point estimates and 95% confidence and prediction intervals:\n",
    "colgpa_PICI_95 = results.get_prediction(cvalues2).summary_frame(\n",
    "    alpha=0.05,\n",
    ")  # alpha=0.05 for 95% intervals\n",
    "# 95% Prediction Interval\n",
    "colgpa_PICI_95"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6da937c",
   "metadata": {},
   "source": [
    "**Interpretation of 95% Intervals:**\n",
    "\n",
    "For \"newPerson1\" (sat=1200, hsperc=30, hsize=5):\n",
    "- **`mean` (Point Prediction):** 2.700\n",
    "- **`mean_ci_lower` and `mean_ci_upper` (95% Confidence Interval for Mean Prediction):** [2.614, 2.786]. We are 95% confident that the *average* college GPA for students with these characteristics falls within this interval.\n",
    "- **`obs_ci_lower` and `obs_ci_upper` (95% Prediction Interval):** [1.744, 3.656]. We are 95% confident that the college GPA for a *specific individual* with these characteristics will fall within this much wider interval.\n",
    "\n",
    "Let's also calculate 99% confidence and prediction intervals (by setting `alpha=0.01`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-20T11:12:21.515843Z",
     "iopub.status.busy": "2025-10-20T11:12:21.515760Z",
     "iopub.status.idle": "2025-10-20T11:12:21.521489Z",
     "shell.execute_reply": "2025-10-20T11:12:21.521263Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>mean_se</th>\n",
       "      <th>mean_ci_lower</th>\n",
       "      <th>mean_ci_upper</th>\n",
       "      <th>obs_ci_lower</th>\n",
       "      <th>obs_ci_upper</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.700075</td>\n",
       "      <td>0.019878</td>\n",
       "      <td>2.648850</td>\n",
       "      <td>2.751301</td>\n",
       "      <td>1.256386</td>\n",
       "      <td>4.143765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.425282</td>\n",
       "      <td>0.014258</td>\n",
       "      <td>2.388540</td>\n",
       "      <td>2.462025</td>\n",
       "      <td>0.982034</td>\n",
       "      <td>3.868530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.457448</td>\n",
       "      <td>0.027891</td>\n",
       "      <td>3.385572</td>\n",
       "      <td>3.529325</td>\n",
       "      <td>2.012879</td>\n",
       "      <td>4.902018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       mean   mean_se  mean_ci_lower  mean_ci_upper  obs_ci_lower  \\\n",
       "0  2.700075  0.019878       2.648850       2.751301      1.256386   \n",
       "1  2.425282  0.014258       2.388540       2.462025      0.982034   \n",
       "2  3.457448  0.027891       3.385572       3.529325      2.012879   \n",
       "\n",
       "   obs_ci_upper  \n",
       "0      4.143765  \n",
       "1      3.868530  \n",
       "2      4.902018  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# point estimates and 99% confidence and prediction intervals:\n",
    "colgpa_PICI_99 = results.get_prediction(cvalues2).summary_frame(\n",
    "    alpha=0.01,\n",
    ")  # alpha=0.01 for 99% intervals\n",
    "# 99% Prediction Interval\n",
    "colgpa_PICI_99"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, the 99% confidence and prediction intervals are wider than the 95% intervals, reflecting the higher level of confidence.\n",
    "\n",
    "### 6.2.2 Effect Plots for Nonlinear Specifications\n",
    "\n",
    "When dealing with nonlinear models, especially those with quadratic terms or interactions, it can be helpful to visualize the predicted relationship between the dependent variable and one independent variable while holding other variables constant.  Effect plots achieve this by showing the predicted values and confidence intervals for a range of values of the variable of interest, keeping other predictors at fixed values (often their means).\n",
    "\n",
    "Let's create an effect plot for the relationship between `rooms` and `lprice` from Example 6.2, holding other variables at their sample means."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-20T11:12:21.522660Z",
     "iopub.status.busy": "2025-10-20T11:12:21.522586Z",
     "iopub.status.idle": "2025-10-20T11:12:21.535742Z",
     "shell.execute_reply": "2025-10-20T11:12:21.535466Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rooms</th>\n",
       "      <th>nox</th>\n",
       "      <th>dist</th>\n",
       "      <th>stratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.549783</td>\n",
       "      <td>3.795751</td>\n",
       "      <td>18.459289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.081633</td>\n",
       "      <td>5.549783</td>\n",
       "      <td>3.795751</td>\n",
       "      <td>18.459289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.163265</td>\n",
       "      <td>5.549783</td>\n",
       "      <td>3.795751</td>\n",
       "      <td>18.459289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.244898</td>\n",
       "      <td>5.549783</td>\n",
       "      <td>3.795751</td>\n",
       "      <td>18.459289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.326531</td>\n",
       "      <td>5.549783</td>\n",
       "      <td>3.795751</td>\n",
       "      <td>18.459289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4.408163</td>\n",
       "      <td>5.549783</td>\n",
       "      <td>3.795751</td>\n",
       "      <td>18.459289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4.489796</td>\n",
       "      <td>5.549783</td>\n",
       "      <td>3.795751</td>\n",
       "      <td>18.459289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4.571429</td>\n",
       "      <td>5.549783</td>\n",
       "      <td>3.795751</td>\n",
       "      <td>18.459289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4.653061</td>\n",
       "      <td>5.549783</td>\n",
       "      <td>3.795751</td>\n",
       "      <td>18.459289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4.734694</td>\n",
       "      <td>5.549783</td>\n",
       "      <td>3.795751</td>\n",
       "      <td>18.459289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>4.816327</td>\n",
       "      <td>5.549783</td>\n",
       "      <td>3.795751</td>\n",
       "      <td>18.459289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>4.897959</td>\n",
       "      <td>5.549783</td>\n",
       "      <td>3.795751</td>\n",
       "      <td>18.459289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>4.979592</td>\n",
       "      <td>5.549783</td>\n",
       "      <td>3.795751</td>\n",
       "      <td>18.459289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>5.061224</td>\n",
       "      <td>5.549783</td>\n",
       "      <td>3.795751</td>\n",
       "      <td>18.459289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>5.142857</td>\n",
       "      <td>5.549783</td>\n",
       "      <td>3.795751</td>\n",
       "      <td>18.459289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>5.224490</td>\n",
       "      <td>5.549783</td>\n",
       "      <td>3.795751</td>\n",
       "      <td>18.459289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>5.306122</td>\n",
       "      <td>5.549783</td>\n",
       "      <td>3.795751</td>\n",
       "      <td>18.459289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>5.387755</td>\n",
       "      <td>5.549783</td>\n",
       "      <td>3.795751</td>\n",
       "      <td>18.459289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>5.469388</td>\n",
       "      <td>5.549783</td>\n",
       "      <td>3.795751</td>\n",
       "      <td>18.459289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>5.551020</td>\n",
       "      <td>5.549783</td>\n",
       "      <td>3.795751</td>\n",
       "      <td>18.459289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>5.632653</td>\n",
       "      <td>5.549783</td>\n",
       "      <td>3.795751</td>\n",
       "      <td>18.459289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>5.714286</td>\n",
       "      <td>5.549783</td>\n",
       "      <td>3.795751</td>\n",
       "      <td>18.459289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>5.795918</td>\n",
       "      <td>5.549783</td>\n",
       "      <td>3.795751</td>\n",
       "      <td>18.459289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>5.877551</td>\n",
       "      <td>5.549783</td>\n",
       "      <td>3.795751</td>\n",
       "      <td>18.459289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>5.959184</td>\n",
       "      <td>5.549783</td>\n",
       "      <td>3.795751</td>\n",
       "      <td>18.459289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>6.040816</td>\n",
       "      <td>5.549783</td>\n",
       "      <td>3.795751</td>\n",
       "      <td>18.459289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>6.122449</td>\n",
       "      <td>5.549783</td>\n",
       "      <td>3.795751</td>\n",
       "      <td>18.459289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>6.204082</td>\n",
       "      <td>5.549783</td>\n",
       "      <td>3.795751</td>\n",
       "      <td>18.459289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>6.285714</td>\n",
       "      <td>5.549783</td>\n",
       "      <td>3.795751</td>\n",
       "      <td>18.459289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>6.367347</td>\n",
       "      <td>5.549783</td>\n",
       "      <td>3.795751</td>\n",
       "      <td>18.459289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>6.448980</td>\n",
       "      <td>5.549783</td>\n",
       "      <td>3.795751</td>\n",
       "      <td>18.459289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>6.530612</td>\n",
       "      <td>5.549783</td>\n",
       "      <td>3.795751</td>\n",
       "      <td>18.459289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>6.612245</td>\n",
       "      <td>5.549783</td>\n",
       "      <td>3.795751</td>\n",
       "      <td>18.459289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>6.693878</td>\n",
       "      <td>5.549783</td>\n",
       "      <td>3.795751</td>\n",
       "      <td>18.459289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>6.775510</td>\n",
       "      <td>5.549783</td>\n",
       "      <td>3.795751</td>\n",
       "      <td>18.459289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>6.857143</td>\n",
       "      <td>5.549783</td>\n",
       "      <td>3.795751</td>\n",
       "      <td>18.459289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>6.938776</td>\n",
       "      <td>5.549783</td>\n",
       "      <td>3.795751</td>\n",
       "      <td>18.459289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>7.020408</td>\n",
       "      <td>5.549783</td>\n",
       "      <td>3.795751</td>\n",
       "      <td>18.459289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>7.102041</td>\n",
       "      <td>5.549783</td>\n",
       "      <td>3.795751</td>\n",
       "      <td>18.459289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>7.183673</td>\n",
       "      <td>5.549783</td>\n",
       "      <td>3.795751</td>\n",
       "      <td>18.459289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>7.265306</td>\n",
       "      <td>5.549783</td>\n",
       "      <td>3.795751</td>\n",
       "      <td>18.459289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>7.346939</td>\n",
       "      <td>5.549783</td>\n",
       "      <td>3.795751</td>\n",
       "      <td>18.459289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>7.428571</td>\n",
       "      <td>5.549783</td>\n",
       "      <td>3.795751</td>\n",
       "      <td>18.459289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>7.510204</td>\n",
       "      <td>5.549783</td>\n",
       "      <td>3.795751</td>\n",
       "      <td>18.459289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>7.591837</td>\n",
       "      <td>5.549783</td>\n",
       "      <td>3.795751</td>\n",
       "      <td>18.459289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>7.673469</td>\n",
       "      <td>5.549783</td>\n",
       "      <td>3.795751</td>\n",
       "      <td>18.459289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>7.755102</td>\n",
       "      <td>5.549783</td>\n",
       "      <td>3.795751</td>\n",
       "      <td>18.459289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>7.836735</td>\n",
       "      <td>5.549783</td>\n",
       "      <td>3.795751</td>\n",
       "      <td>18.459289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>7.918367</td>\n",
       "      <td>5.549783</td>\n",
       "      <td>3.795751</td>\n",
       "      <td>18.459289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>8.000000</td>\n",
       "      <td>5.549783</td>\n",
       "      <td>3.795751</td>\n",
       "      <td>18.459289</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       rooms       nox      dist    stratio\n",
       "0   4.000000  5.549783  3.795751  18.459289\n",
       "1   4.081633  5.549783  3.795751  18.459289\n",
       "2   4.163265  5.549783  3.795751  18.459289\n",
       "3   4.244898  5.549783  3.795751  18.459289\n",
       "4   4.326531  5.549783  3.795751  18.459289\n",
       "5   4.408163  5.549783  3.795751  18.459289\n",
       "6   4.489796  5.549783  3.795751  18.459289\n",
       "7   4.571429  5.549783  3.795751  18.459289\n",
       "8   4.653061  5.549783  3.795751  18.459289\n",
       "9   4.734694  5.549783  3.795751  18.459289\n",
       "10  4.816327  5.549783  3.795751  18.459289\n",
       "11  4.897959  5.549783  3.795751  18.459289\n",
       "12  4.979592  5.549783  3.795751  18.459289\n",
       "13  5.061224  5.549783  3.795751  18.459289\n",
       "14  5.142857  5.549783  3.795751  18.459289\n",
       "15  5.224490  5.549783  3.795751  18.459289\n",
       "16  5.306122  5.549783  3.795751  18.459289\n",
       "17  5.387755  5.549783  3.795751  18.459289\n",
       "18  5.469388  5.549783  3.795751  18.459289\n",
       "19  5.551020  5.549783  3.795751  18.459289\n",
       "20  5.632653  5.549783  3.795751  18.459289\n",
       "21  5.714286  5.549783  3.795751  18.459289\n",
       "22  5.795918  5.549783  3.795751  18.459289\n",
       "23  5.877551  5.549783  3.795751  18.459289\n",
       "24  5.959184  5.549783  3.795751  18.459289\n",
       "25  6.040816  5.549783  3.795751  18.459289\n",
       "26  6.122449  5.549783  3.795751  18.459289\n",
       "27  6.204082  5.549783  3.795751  18.459289\n",
       "28  6.285714  5.549783  3.795751  18.459289\n",
       "29  6.367347  5.549783  3.795751  18.459289\n",
       "30  6.448980  5.549783  3.795751  18.459289\n",
       "31  6.530612  5.549783  3.795751  18.459289\n",
       "32  6.612245  5.549783  3.795751  18.459289\n",
       "33  6.693878  5.549783  3.795751  18.459289\n",
       "34  6.775510  5.549783  3.795751  18.459289\n",
       "35  6.857143  5.549783  3.795751  18.459289\n",
       "36  6.938776  5.549783  3.795751  18.459289\n",
       "37  7.020408  5.549783  3.795751  18.459289\n",
       "38  7.102041  5.549783  3.795751  18.459289\n",
       "39  7.183673  5.549783  3.795751  18.459289\n",
       "40  7.265306  5.549783  3.795751  18.459289\n",
       "41  7.346939  5.549783  3.795751  18.459289\n",
       "42  7.428571  5.549783  3.795751  18.459289\n",
       "43  7.510204  5.549783  3.795751  18.459289\n",
       "44  7.591837  5.549783  3.795751  18.459289\n",
       "45  7.673469  5.549783  3.795751  18.459289\n",
       "46  7.755102  5.549783  3.795751  18.459289\n",
       "47  7.836735  5.549783  3.795751  18.459289\n",
       "48  7.918367  5.549783  3.795751  18.459289\n",
       "49  8.000000  5.549783  3.795751  18.459289"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hprice2 = wool.data(\"hprice2\")\n",
    "\n",
    "# repeating the regression from Example 6.2:\n",
    "reg = smf.ols(\n",
    "    formula=\"np.log(price) ~ np.log(nox)+np.log(dist)+rooms+I(rooms**2)+stratio\",\n",
    "    data=hprice2,\n",
    ")\n",
    "results = reg.fit()\n",
    "\n",
    "# predictions with rooms = 4-8, all others at the sample mean:\n",
    "nox_mean = np.mean(hprice2[\"nox\"])\n",
    "dist_mean = np.mean(hprice2[\"dist\"])\n",
    "stratio_mean = np.mean(hprice2[\"stratio\"])\n",
    "X = pd.DataFrame(\n",
    "    {\n",
    "        \"rooms\": np.linspace(4, 8, num=50),  # Generate a range of rooms values\n",
    "        \"nox\": nox_mean,\n",
    "        \"dist\": dist_mean,\n",
    "        \"stratio\": stratio_mean,\n",
    "    },\n",
    ")\n",
    "# Design matrix for log(price) prediction\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94b0d3e7",
   "metadata": {},
   "source": [
    "We create a DataFrame `X` where `rooms` varies from 4 to 8 (a reasonable range for house rooms), and `nox`, `dist`, and `stratio` are held at their sample means.  Then, we calculate the predicted values and confidence intervals for these values of `rooms`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-20T11:12:21.536990Z",
     "iopub.status.busy": "2025-10-20T11:12:21.536906Z",
     "iopub.status.idle": "2025-10-20T11:12:21.544433Z",
     "shell.execute_reply": "2025-10-20T11:12:21.544197Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>mean_ci_lower</th>\n",
       "      <th>mean_ci_upper</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9.661702</td>\n",
       "      <td>9.499811</td>\n",
       "      <td>9.823593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9.658279</td>\n",
       "      <td>9.506128</td>\n",
       "      <td>9.810429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9.655685</td>\n",
       "      <td>9.512931</td>\n",
       "      <td>9.798438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9.653920</td>\n",
       "      <td>9.520219</td>\n",
       "      <td>9.787622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9.652986</td>\n",
       "      <td>9.527991</td>\n",
       "      <td>9.777981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>9.652882</td>\n",
       "      <td>9.536244</td>\n",
       "      <td>9.769519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>9.653607</td>\n",
       "      <td>9.544977</td>\n",
       "      <td>9.762236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>9.655162</td>\n",
       "      <td>9.554187</td>\n",
       "      <td>9.756136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9.657547</td>\n",
       "      <td>9.563871</td>\n",
       "      <td>9.751222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9.660762</td>\n",
       "      <td>9.574025</td>\n",
       "      <td>9.747498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>9.664806</td>\n",
       "      <td>9.584645</td>\n",
       "      <td>9.744967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>9.669680</td>\n",
       "      <td>9.595726</td>\n",
       "      <td>9.743635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>9.675384</td>\n",
       "      <td>9.607261</td>\n",
       "      <td>9.743508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>9.681918</td>\n",
       "      <td>9.619244</td>\n",
       "      <td>9.744593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>9.689282</td>\n",
       "      <td>9.631666</td>\n",
       "      <td>9.746898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>9.697476</td>\n",
       "      <td>9.644520</td>\n",
       "      <td>9.750431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>9.706499</td>\n",
       "      <td>9.657795</td>\n",
       "      <td>9.755202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>9.716352</td>\n",
       "      <td>9.671483</td>\n",
       "      <td>9.761221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>9.727035</td>\n",
       "      <td>9.685573</td>\n",
       "      <td>9.768497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>9.738548</td>\n",
       "      <td>9.700060</td>\n",
       "      <td>9.777035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>9.750890</td>\n",
       "      <td>9.714940</td>\n",
       "      <td>9.786840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>9.764062</td>\n",
       "      <td>9.730218</td>\n",
       "      <td>9.797907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>9.778065</td>\n",
       "      <td>9.745903</td>\n",
       "      <td>9.810226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>9.792897</td>\n",
       "      <td>9.762017</td>\n",
       "      <td>9.823776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>9.808558</td>\n",
       "      <td>9.778588</td>\n",
       "      <td>9.838529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>9.825050</td>\n",
       "      <td>9.795652</td>\n",
       "      <td>9.854448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>9.842371</td>\n",
       "      <td>9.813249</td>\n",
       "      <td>9.871493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>9.860522</td>\n",
       "      <td>9.831420</td>\n",
       "      <td>9.889625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>9.879503</td>\n",
       "      <td>9.850199</td>\n",
       "      <td>9.908807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>9.899314</td>\n",
       "      <td>9.869617</td>\n",
       "      <td>9.929011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>9.919955</td>\n",
       "      <td>9.889694</td>\n",
       "      <td>9.950216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>9.941425</td>\n",
       "      <td>9.910440</td>\n",
       "      <td>9.972410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>9.963725</td>\n",
       "      <td>9.931858</td>\n",
       "      <td>9.995593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>9.986855</td>\n",
       "      <td>9.953941</td>\n",
       "      <td>10.019769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>10.010815</td>\n",
       "      <td>9.976677</td>\n",
       "      <td>10.044952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>10.035604</td>\n",
       "      <td>10.000049</td>\n",
       "      <td>10.071160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>10.061224</td>\n",
       "      <td>10.024033</td>\n",
       "      <td>10.098415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>10.087673</td>\n",
       "      <td>10.048607</td>\n",
       "      <td>10.126739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>10.114952</td>\n",
       "      <td>10.073748</td>\n",
       "      <td>10.156156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>10.143061</td>\n",
       "      <td>10.099434</td>\n",
       "      <td>10.186688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>10.171999</td>\n",
       "      <td>10.125645</td>\n",
       "      <td>10.218354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>10.201768</td>\n",
       "      <td>10.152364</td>\n",
       "      <td>10.251171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>10.232366</td>\n",
       "      <td>10.179579</td>\n",
       "      <td>10.285153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>10.263794</td>\n",
       "      <td>10.207278</td>\n",
       "      <td>10.320310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>10.296052</td>\n",
       "      <td>10.235454</td>\n",
       "      <td>10.356650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>10.329139</td>\n",
       "      <td>10.264101</td>\n",
       "      <td>10.394178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>10.363057</td>\n",
       "      <td>10.293217</td>\n",
       "      <td>10.432897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>10.397804</td>\n",
       "      <td>10.322799</td>\n",
       "      <td>10.472810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>10.433381</td>\n",
       "      <td>10.352847</td>\n",
       "      <td>10.513916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>10.469788</td>\n",
       "      <td>10.383361</td>\n",
       "      <td>10.556215</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         mean  mean_ci_lower  mean_ci_upper\n",
       "0    9.661702       9.499811       9.823593\n",
       "1    9.658279       9.506128       9.810429\n",
       "2    9.655685       9.512931       9.798438\n",
       "3    9.653920       9.520219       9.787622\n",
       "4    9.652986       9.527991       9.777981\n",
       "5    9.652882       9.536244       9.769519\n",
       "6    9.653607       9.544977       9.762236\n",
       "7    9.655162       9.554187       9.756136\n",
       "8    9.657547       9.563871       9.751222\n",
       "9    9.660762       9.574025       9.747498\n",
       "10   9.664806       9.584645       9.744967\n",
       "11   9.669680       9.595726       9.743635\n",
       "12   9.675384       9.607261       9.743508\n",
       "13   9.681918       9.619244       9.744593\n",
       "14   9.689282       9.631666       9.746898\n",
       "15   9.697476       9.644520       9.750431\n",
       "16   9.706499       9.657795       9.755202\n",
       "17   9.716352       9.671483       9.761221\n",
       "18   9.727035       9.685573       9.768497\n",
       "19   9.738548       9.700060       9.777035\n",
       "20   9.750890       9.714940       9.786840\n",
       "21   9.764062       9.730218       9.797907\n",
       "22   9.778065       9.745903       9.810226\n",
       "23   9.792897       9.762017       9.823776\n",
       "24   9.808558       9.778588       9.838529\n",
       "25   9.825050       9.795652       9.854448\n",
       "26   9.842371       9.813249       9.871493\n",
       "27   9.860522       9.831420       9.889625\n",
       "28   9.879503       9.850199       9.908807\n",
       "29   9.899314       9.869617       9.929011\n",
       "30   9.919955       9.889694       9.950216\n",
       "31   9.941425       9.910440       9.972410\n",
       "32   9.963725       9.931858       9.995593\n",
       "33   9.986855       9.953941      10.019769\n",
       "34  10.010815       9.976677      10.044952\n",
       "35  10.035604      10.000049      10.071160\n",
       "36  10.061224      10.024033      10.098415\n",
       "37  10.087673      10.048607      10.126739\n",
       "38  10.114952      10.073748      10.156156\n",
       "39  10.143061      10.099434      10.186688\n",
       "40  10.171999      10.125645      10.218354\n",
       "41  10.201768      10.152364      10.251171\n",
       "42  10.232366      10.179579      10.285153\n",
       "43  10.263794      10.207278      10.320310\n",
       "44  10.296052      10.235454      10.356650\n",
       "45  10.329139      10.264101      10.394178\n",
       "46  10.363057      10.293217      10.432897\n",
       "47  10.397804      10.322799      10.472810\n",
       "48  10.433381      10.352847      10.513916\n",
       "49  10.469788      10.383361      10.556215"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate 95% confidence interval:\n",
    "lpr_PICI = results.get_prediction(X).summary_frame(alpha=0.05)\n",
    "lpr_CI = lpr_PICI[\n",
    "    [\"mean\", \"mean_ci_lower\", \"mean_ci_upper\"]\n",
    "]  # Extract mean and CI bounds\n",
    "# Confidence interval for log(price)\n",
    "lpr_CI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eac8a43",
   "metadata": {},
   "source": [
    "Finally, we plot the predicted log price and its confidence interval against the number of rooms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-20T11:12:21.545979Z",
     "iopub.status.busy": "2025-10-20T11:12:21.545854Z",
     "iopub.status.idle": "2025-10-20T11:12:21.563492Z",
     "shell.execute_reply": "2025-10-20T11:12:21.563233Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/rg/vmn_nq41613gkxt0_9spwzx80000gp/T/ipykernel_8305/200676822.py:28: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  plt.show()\n"
     ]
    }
   ],
   "source": [
    "# plot:\n",
    "plt.plot(\n",
    "    X[\"rooms\"],\n",
    "    lpr_CI[\"mean\"],\n",
    "    color=\"black\",\n",
    "    linestyle=\"-\",\n",
    "    label=\"Predicted lprice\",\n",
    ")  # Plot predicted mean\n",
    "plt.plot(\n",
    "    X[\"rooms\"],\n",
    "    lpr_CI[\"mean_ci_upper\"],\n",
    "    color=\"lightgrey\",\n",
    "    linestyle=\"--\",\n",
    "    label=\"Upper 95% CI\",  # Plot upper CI bound\n",
    ")\n",
    "plt.plot(\n",
    "    X[\"rooms\"],\n",
    "    lpr_CI[\"mean_ci_lower\"],\n",
    "    color=\"darkgrey\",\n",
    "    linestyle=\"--\",\n",
    "    label=\"Lower 95% CI\",  # Plot lower CI bound\n",
    ")\n",
    "plt.ylabel(\"Log of Price (lprice)\")\n",
    "plt.xlabel(\"Number of Rooms (rooms)\")\n",
    "plt.title(\"Effect of Number of Rooms on Log Price (holding other variables at means)\")\n",
    "plt.legend()\n",
    "plt.grid(True)  # Add grid for better readability\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e81e903e",
   "metadata": {},
   "source": [
    "**Interpretation of Effect Plot:**\n",
    "\n",
    "The plot visually represents the inverted U-shaped relationship between the number of rooms and the log of housing price, as suggested by the regression coefficients.  The shaded area between the dashed lines represents the 95% confidence interval for the mean prediction.  This plot helps to understand the nonlinear effect of `rooms` on `lprice` and the uncertainty associated with these predictions. Effect plots are valuable tools for interpreting and presenting results from regression models with nonlinear specifications.\n",
    "\n",
    "## 6.3 Goodness-of-Fit and Model Selection\n",
    "\n",
    "When working with multiple regression models, we often need to compare different specifications to determine which provides the best fit or explanatory power. This section covers tools for assessing model fit and selecting among competing models.\n",
    "\n",
    "### 6.3.1 Adjusted R-Squared\n",
    "\n",
    "Recall that the **R-squared** measures the proportion of variation in $y$ explained by the regression:\n",
    "\n",
    "$$R^2 = 1 - \\frac{SSR}{SST} = 1 - \\frac{\\sum_{i=1}^n \\hat{u}_i^2}{\\sum_{i=1}^n (y_i - \\bar{y})^2}$$\n",
    "\n",
    "**Problem with R-squared**: It **never decreases** when adding variables, even irrelevant ones! This creates a bias toward including more variables.\n",
    "\n",
    "**Solution: Adjusted R-squared**\n",
    "\n",
    "$$\\bar{R}^2 = 1 - \\frac{SSR/(n-k-1)}{SST/(n-1)} = 1 - \\frac{n-1}{n-k-1}(1 - R^2)$$\n",
    "\n",
    "where:\n",
    "- $n$ = sample size\n",
    "- $k$ = number of independent variables (not including intercept)\n",
    "- $SSR/(n-k-1) = \\hat{\\sigma}^2$ = unbiased estimate of error variance\n",
    "\n",
    "**Key Properties:**\n",
    "\n",
    "1. **Penalizes for adding variables**: $\\bar{R}^2$ can decrease when adding a variable\n",
    "2. **Compares models**: Higher $\\bar{R}^2$ suggests better model (among nested models)\n",
    "3. **Can be negative**: Unlike $R^2$, $\\bar{R}^2$ can be negative if model fits poorly\n",
    "4. **Formula insight**: $\\bar{R}^2 < R^2$ always, with gap increasing as more variables are added\n",
    "\n",
    "**When to Prefer Adjusted R-squared:**\n",
    "\n",
    "- Comparing models with **different numbers of variables**\n",
    "- Assessing whether an added variable improves fit enough to justify complexity\n",
    "- Avoiding overfitting in model selection\n",
    "\n",
    "**Example: Comparing Models with Adjusted R-squared**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3c4e2b9e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-20T11:12:21.564736Z",
     "iopub.status.busy": "2025-10-20T11:12:21.564656Z",
     "iopub.status.idle": "2025-10-20T11:12:21.581263Z",
     "shell.execute_reply": "2025-10-20T11:12:21.581030Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>R-squared</th>\n",
       "      <th>Adj R-squared</th>\n",
       "      <th>n</th>\n",
       "      <th>k</th>\n",
       "      <th>Assessment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model 1 (3 vars)</td>\n",
       "      <td>0.643</td>\n",
       "      <td>0.6302</td>\n",
       "      <td>88.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Baseline</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Model 2 (5 vars)</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>88.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Better</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Model 3 (6 vars)</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>88.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Better</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Model  R-squared  Adj R-squared     n    k Assessment\n",
       "0  Model 1 (3 vars)      0.643         0.6302  88.0  3.0   Baseline\n",
       "1  Model 2 (5 vars)      1.000         1.0000  88.0  5.0     Better\n",
       "2  Model 3 (6 vars)      1.000         1.0000  88.0  6.0     Better"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Compare models with different numbers of variables\n",
    "import wooldridge as woo\n",
    "\n",
    "# Load data\n",
    "hprice1 = woo.data('hprice1')\n",
    "\n",
    "# Model 1: Simple model with key variables\n",
    "model1 = smf.ols('np.log(price) ~ np.log(lotsize) + np.log(sqrft) + bdrms', data=hprice1).fit()\n",
    "\n",
    "# Model 2: Add more variables\n",
    "model2 = smf.ols('np.log(price) ~ np.log(lotsize) + np.log(sqrft) + bdrms + colonial + lprice', data=hprice1).fit()\n",
    "\n",
    "# Model 3: Add even more variables\n",
    "model3 = smf.ols('np.log(price) ~ np.log(lotsize) + np.log(sqrft) + bdrms + colonial + lprice + np.log(lotsize):bdrms', data=hprice1).fit()\n",
    "\n",
    "# Compare fit statistics\n",
    "comparison = pd.DataFrame({\n",
    "    'Model': ['Model 1 (3 vars)', 'Model 2 (5 vars)', 'Model 3 (6 vars)'],\n",
    "    'R-squared': [model1.rsquared, model2.rsquared, model3.rsquared],\n",
    "    'Adj R-squared': [model1.rsquared_adj, model2.rsquared_adj, model3.rsquared_adj],\n",
    "    'n': [model1.nobs, model2.nobs, model3.nobs],\n",
    "    'k': [model1.df_model, model2.df_model, model3.df_model],\n",
    "    'Assessment': [\n",
    "        'Baseline',\n",
    "        'Better' if model2.rsquared_adj > model1.rsquared_adj else 'Worse',\n",
    "        'Better' if model3.rsquared_adj > model2.rsquared_adj else 'Worse'\n",
    "    ]\n",
    "})\n",
    "\n",
    "display(comparison.round(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80806252",
   "metadata": {},
   "source": [
    "**Interpretation**: \n",
    "- R-squared increases with every variable added (mechanical property)\n",
    "- Adjusted R-squared may decrease if added variable doesn't improve fit enough\n",
    "- Choose model with highest adjusted R-squared among reasonable specifications\n",
    "\n",
    "### 6.3.2 Model Selection Criteria: AIC and BIC\n",
    "\n",
    "While adjusted R-squared is intuitive, more sophisticated model selection criteria are often preferred in practice.\n",
    "\n",
    "**Akaike Information Criterion (AIC)**:\n",
    "\n",
    "$$AIC = n \\ln(SSR/n) + 2(k+1)$$\n",
    "\n",
    "**Bayesian Information Criterion (BIC)**:\n",
    "\n",
    "$$BIC = n \\ln(SSR/n) + \\ln(n)(k+1)$$\n",
    "\n",
    "**Key Differences:**\n",
    "\n",
    "1. **Penalty strength**: BIC penalizes model complexity more heavily than AIC (when $n > 7$)\n",
    "2. **Interpretation**: Lower values indicate better models (opposite of R-squared!)\n",
    "3. **Consistency**: BIC is consistent (selects true model as $n \\to \\infty$), AIC is not\n",
    "4. **Practical use**: BIC tends to select simpler models than AIC\n",
    "\n",
    "**Example: Model Selection with AIC and BIC**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dea1ea1a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-20T11:12:21.582696Z",
     "iopub.status.busy": "2025-10-20T11:12:21.582597Z",
     "iopub.status.idle": "2025-10-20T11:12:21.587757Z",
     "shell.execute_reply": "2025-10-20T11:12:21.587517Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>AIC</th>\n",
       "      <th>BIC</th>\n",
       "      <th>Adj R-sq</th>\n",
       "      <th>Best by AIC</th>\n",
       "      <th>Best by BIC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model 1</td>\n",
       "      <td>-43.72</td>\n",
       "      <td>-33.81</td>\n",
       "      <td>0.63</td>\n",
       "      <td>NO</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Model 2</td>\n",
       "      <td>-2551.05</td>\n",
       "      <td>-2536.19</td>\n",
       "      <td>1.00</td>\n",
       "      <td>YES</td>\n",
       "      <td>YES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Model 3</td>\n",
       "      <td>-2550.80</td>\n",
       "      <td>-2533.46</td>\n",
       "      <td>1.00</td>\n",
       "      <td>NO</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Model      AIC      BIC  Adj R-sq Best by AIC Best by BIC\n",
       "0  Model 1   -43.72   -33.81      0.63          NO          NO\n",
       "1  Model 2 -2551.05 -2536.19      1.00         YES         YES\n",
       "2  Model 3 -2550.80 -2533.46      1.00          NO          NO"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Calculate AIC and BIC for models\n",
    "model_selection = pd.DataFrame({\n",
    "    'Model': ['Model 1', 'Model 2', 'Model 3'],\n",
    "    'AIC': [model1.aic, model2.aic, model3.aic],\n",
    "    'BIC': [model1.bic, model2.bic, model3.bic],\n",
    "    'Adj R-sq': [model1.rsquared_adj, model2.rsquared_adj, model3.rsquared_adj],\n",
    "    'Best by AIC': ['YES' if model1.aic == min([model1.aic, model2.aic, model3.aic]) else 'NO',\n",
    "                     'YES' if model2.aic == min([model1.aic, model2.aic, model3.aic]) else 'NO',\n",
    "                     'YES' if model3.aic == min([model1.aic, model2.aic, model3.aic]) else 'NO'],\n",
    "    'Best by BIC': ['YES' if model1.bic == min([model1.bic, model2.bic, model3.bic]) else 'NO',\n",
    "                     'YES' if model2.bic == min([model1.bic, model2.bic, model3.bic]) else 'NO',\n",
    "                     'YES' if model3.bic == min([model1.bic, model2.bic, model3.bic]) else 'NO']\n",
    "})\n",
    "\n",
    "display(model_selection.round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79e5f4af",
   "metadata": {},
   "source": [
    "**When Criteria Disagree:**\n",
    "\n",
    "- AIC may prefer more complex model (lower penalty for parameters)\n",
    "- BIC may prefer simpler model (higher penalty for parameters)\n",
    "- Consider: economic theory, out-of-sample performance, interpretability\n",
    "\n",
    "### 6.3.3 The Problem of Controlling for Too Many Variables\n",
    "\n",
    "**More variables is not always better!** Over-controlling can cause problems:\n",
    "\n",
    "**1. Multicollinearity**: \n",
    "- Adding many correlated variables inflates standard errors\n",
    "- Reduces statistical power to detect effects\n",
    "- Makes estimates unstable across samples\n",
    "\n",
    "**2. Post-treatment bias** (from Chapter 3):\n",
    "- Including variables affected by treatment blocks causal pathways\n",
    "- Underestimates total effects\n",
    "\n",
    "**3. Overfitting**:\n",
    "- Model fits sample noise instead of population relationship\n",
    "- Poor out-of-sample prediction\n",
    "- False sense of precision\n",
    "\n",
    "**4. Degrees of freedom loss**:\n",
    "- With $k$ close to $n$, little information for estimation\n",
    "- Standard errors become unreliable\n",
    "- R-squared artificially high\n",
    "\n",
    "**Example: Overfitting Demonstration**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "55e741fd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-20T11:12:21.588942Z",
     "iopub.status.busy": "2025-10-20T11:12:21.588862Z",
     "iopub.status.idle": "2025-10-20T11:12:21.603661Z",
     "shell.execute_reply": "2025-10-20T11:12:21.603438Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>R-squared</th>\n",
       "      <th>Adj R-squared</th>\n",
       "      <th>AIC</th>\n",
       "      <th>BIC</th>\n",
       "      <th>SE(x1)</th>\n",
       "      <th>Assessment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Simple (True)</td>\n",
       "      <td>0.6641</td>\n",
       "      <td>0.6571</td>\n",
       "      <td>206.3576</td>\n",
       "      <td>210.1817</td>\n",
       "      <td>0.2859</td>\n",
       "      <td>Better (simpler, more precise)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Overfit (11 vars)</td>\n",
       "      <td>0.7479</td>\n",
       "      <td>0.6749</td>\n",
       "      <td>212.0012</td>\n",
       "      <td>234.9455</td>\n",
       "      <td>0.2942</td>\n",
       "      <td>Worse (overfit, imprecise)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Model  R-squared  Adj R-squared       AIC       BIC  SE(x1)  \\\n",
       "0      Simple (True)     0.6641         0.6571  206.3576  210.1817  0.2859   \n",
       "1  Overfit (11 vars)     0.7479         0.6749  212.0012  234.9455  0.2942   \n",
       "\n",
       "                       Assessment  \n",
       "0  Better (simpler, more precise)  \n",
       "1      Worse (overfit, imprecise)  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Demonstrate overfitting with too many variables\n",
    "np.random.seed(42)\n",
    "n = 50  # Small sample\n",
    "\n",
    "# True DGP: y depends only on x1\n",
    "x1 = stats.norm.rvs(0, 1, size=n)\n",
    "x_noise = stats.norm.rvs(0, 1, size=(n, 10))  # 10 irrelevant variables\n",
    "y_true = 2 + 3 * x1\n",
    "y = y_true + stats.norm.rvs(0, 2, size=n)\n",
    "\n",
    "# Create dataframe\n",
    "data_overfit = pd.DataFrame({'y': y, 'x1': x1})\n",
    "for i in range(10):\n",
    "    data_overfit[f'noise{i+1}'] = x_noise[:, i]\n",
    "\n",
    "# Simple model (correct specification)\n",
    "simple_model = smf.ols('y ~ x1', data=data_overfit).fit()\n",
    "\n",
    "# Overfit model (includes irrelevant variables)\n",
    "overfit_formula = 'y ~ x1 + ' + ' + '.join([f'noise{i+1}' for i in range(10)])\n",
    "overfit_model = smf.ols(overfit_formula, data=data_overfit).fit()\n",
    "\n",
    "# Compare\n",
    "overfit_comparison = pd.DataFrame({\n",
    "    'Model': ['Simple (True)', 'Overfit (11 vars)'],\n",
    "    'R-squared': [simple_model.rsquared, overfit_model.rsquared],\n",
    "    'Adj R-squared': [simple_model.rsquared_adj, overfit_model.rsquared_adj],\n",
    "    'AIC': [simple_model.aic, overfit_model.aic],\n",
    "    'BIC': [simple_model.bic, overfit_model.bic],\n",
    "    'SE(x1)': [simple_model.bse['x1'], overfit_model.bse['x1']],\n",
    "    'Assessment': ['Better (simpler, more precise)', 'Worse (overfit, imprecise)']\n",
    "})\n",
    "\n",
    "display(overfit_comparison.round(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e77d056",
   "metadata": {},
   "source": [
    "**Lessons:**\n",
    "- R-squared higher in overfit model (misleading!)\n",
    "- Adjusted R-squared, AIC, BIC all prefer simple model\n",
    "- Standard error on x1 inflated in overfit model (less precision)\n",
    "- **Occam's Razor**: Prefer simpler models when in doubt\n",
    "\n",
    ":::{warning} Guidelines for Variable Inclusion\n",
    ":class: dropdown\n",
    "\n",
    "**DO include variables if:**\n",
    "- Economic theory suggests they're important confounders\n",
    "- Omitting them would cause bias in key coefficient\n",
    "- They significantly improve fit (F-test, adjusted R-squared)\n",
    "- They're needed for policy evaluation\n",
    "\n",
    "**DON'T include variables if:**\n",
    "- They're post-treatment outcomes\n",
    "- They're perfectly correlated with other variables\n",
    "- They're only included to maximize R-squared\n",
    "- You're on a \"fishing expedition\" for significance\n",
    "\n",
    "**Rule of Thumb**: Aim for roughly $n/10$ to $n/20$ variables maximum. With $n=100$, keep $k \\leq 5-10$.\n",
    ":::\n",
    "\n",
    "### 6.3.4 Log Transformation Special Cases\n",
    "\n",
    "**Problem with log(0):**\n",
    "\n",
    "Variables like income, sales, or participation rates can be zero. Taking $\\log(0)$ is undefined!\n",
    "\n",
    "**Common \"Solution\": log(1 + y)**\n",
    "\n",
    "Some researchers use $\\log(1 + y)$ to handle zeros:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0df25401",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-20T11:12:21.604799Z",
     "iopub.status.busy": "2025-10-20T11:12:21.604722Z",
     "iopub.status.idle": "2025-10-20T11:12:21.606468Z",
     "shell.execute_reply": "2025-10-20T11:12:21.606162Z"
    }
   },
   "outputs": [],
   "source": [
    "# Example with zeros\n",
    "income = np.array([0, 1000, 5000, 10000, 50000])\n",
    "log_income_plus1 = np.log(1 + income)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34ae9743",
   "metadata": {},
   "source": [
    "**Problems with log(1 + y):**\n",
    "\n",
    "1. **Interpretation changes**: Coefficient no longer represents percentage change\n",
    "   - With $\\log(y)$: 1-unit change in $x$  $100\\beta$ percent change in $y$\n",
    "   - With $\\log(1+y)$: Interpretation unclear, especially when $y$ is large\n",
    "\n",
    "2. **Asymmetry**: Works differently for small vs large values\n",
    "   - $\\log(1 + 1) = 0.693$\n",
    "   - $\\log(1 + 1000) = 6.908$\n",
    "   - Transformation more dramatic for small values\n",
    "\n",
    "3. **Economic implausibility**: Adding 1 to income or sales lacks economic meaning\n",
    "\n",
    "**Better Alternatives:**\n",
    "\n",
    "1. **Inverse hyperbolic sine (IHS)**: $\\text{asinh}(y) = \\log(y + \\sqrt{y^2 + 1})$\n",
    "   - Handles zeros and negatives\n",
    "   - Approximately $\\log(y)$ for large $y$\n",
    "   - More interpretable than $\\log(1+y)$\n",
    "\n",
    "2. **Tobit model** (Chapter 17): Explicitly model zeros as censoring\n",
    "\n",
    "3. **Two-part model**: Model (1) whether $y > 0$ and (2) level of $y$ given $y > 0$\n",
    "\n",
    "**Predicting Levels from Log Models:**\n",
    "\n",
    "When dependent variable is $\\log(y)$, predicting the **level** of $y$ requires care:\n",
    "\n",
    "**Naive (WRONG)**:\n",
    "$$\\hat{y} = \\exp(\\hat{\\beta}_0 + \\hat{\\beta}_1 x_1 + \\cdots + \\hat{\\beta}_k x_k)$$\n",
    "\n",
    "**Corrected (semi-log retransformation)**:\n",
    "$$\\hat{y} = \\exp(\\hat{\\beta}_0 + \\hat{\\beta}_1 x_1 + \\cdots + \\hat{\\beta}_k x_k) \\times \\exp(\\hat{\\sigma}^2/2)$$\n",
    "\n",
    "where $\\hat{\\sigma}^2 = SSR/(n-k-1)$.\n",
    "\n",
    "**Reason**: Jensen's inequality - $E[\\exp(u)] \\neq \\exp(E[u])$ when $u$ is random.\n",
    "\n",
    "**Example: Correct Prediction from Log Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f0a2aad9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-20T11:12:21.607729Z",
     "iopub.status.busy": "2025-10-20T11:12:21.607631Z",
     "iopub.status.idle": "2025-10-20T11:12:21.619206Z",
     "shell.execute_reply": "2025-10-20T11:12:21.618939Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Method</th>\n",
       "      <th>Value</th>\n",
       "      <th>Interpretation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Predicted log(wage)</td>\n",
       "      <td>1.9084</td>\n",
       "      <td>Log scale</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Naive: exp(predicted)</td>\n",
       "      <td>6.7421</td>\n",
       "      <td>Underestimates true expected wage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Corrected: exp(pred) * correction</td>\n",
       "      <td>7.4302</td>\n",
       "      <td>Proper prediction of expected wage level</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Method   Value  \\\n",
       "0                Predicted log(wage)  1.9084   \n",
       "1              Naive: exp(predicted)  6.7421   \n",
       "2  Corrected: exp(pred) * correction  7.4302   \n",
       "\n",
       "                             Interpretation  \n",
       "0                                 Log scale  \n",
       "1         Underestimates true expected wage  \n",
       "2  Proper prediction of expected wage level  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Estimate wage equation\n",
    "wage1 = woo.data('wage1')\n",
    "log_wage_model = smf.ols('np.log(wage) ~ educ + exper + tenure', data=wage1).fit()\n",
    "\n",
    "# Predict for specific person\n",
    "new_person = pd.DataFrame({'educ': [16], 'exper': [10], 'tenure': [5]})\n",
    "\n",
    "# Naive prediction (WRONG)\n",
    "log_wage_pred = log_wage_model.predict(new_person)\n",
    "wage_naive = np.exp(log_wage_pred.values[0])\n",
    "\n",
    "# Corrected prediction (RIGHT)\n",
    "sigma_sq = log_wage_model.mse_resid  # = SSR / (n-k-1)\n",
    "smearing_factor = np.exp(sigma_sq / 2)\n",
    "wage_corrected = np.exp(log_wage_pred.values[0]) * smearing_factor\n",
    "\n",
    "retransform_comparison = pd.DataFrame({\n",
    "    'Method': ['Predicted log(wage)', 'Naive: exp(predicted)', 'Corrected: exp(pred) * correction'],\n",
    "    'Value': [log_wage_pred.values[0], wage_naive, wage_corrected],\n",
    "    'Interpretation': [\n",
    "        'Log scale',\n",
    "        'Underestimates true expected wage',\n",
    "        'Proper prediction of expected wage level'\n",
    "    ]\n",
    "})\n",
    "\n",
    "display(retransform_comparison.round(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0f4b5ba",
   "metadata": {},
   "source": [
    "## 6.4 Residual Analysis\n",
    "\n",
    "**Residuals** ($\\hat{u}_i = y_i - \\hat{y}_i$) provide crucial diagnostic information about model adequacy. Systematic patterns in residuals signal violations of Gauss-Markov assumptions.\n",
    "\n",
    "### 6.4.1 What Residuals Should Look Like\n",
    "\n",
    "Under the classical assumptions (MLR.1-MLR.6), residuals should:\n",
    "\n",
    "1. **Have mean zero** (guaranteed by OLS)\n",
    "2. **Be uncorrelated with predictors** (guaranteed by OLS)\n",
    "3. **Have constant variance** (homoskedasticity, MLR.5)\n",
    "4. **Show no patterns** when plotted against fitted values or predictors\n",
    "5. **Be approximately normal** (MLR.6, less critical for large samples)\n",
    "\n",
    "### 6.4.2 Residual Plots for Diagnostics\n",
    "\n",
    "**Plot 1: Residuals vs Fitted Values**\n",
    "\n",
    "Most important diagnostic plot! Look for:\n",
    "- **Horizontal band**: Good (homoskedasticity)\n",
    "- **Funnel shape**: Heteroskedasticity (Chapter 8)\n",
    "- **Curved pattern**: Functional form misspecification\n",
    "- **Outliers**: Influential observations\n",
    "\n",
    "**Plot 2: Residuals vs Each Predictor**\n",
    "\n",
    "Checks for:\n",
    "- Nonlinear relationships missed by model\n",
    "- Need for quadratic or interaction terms\n",
    "\n",
    "**Plot 3: Q-Q Plot (Quantile-Quantile)**\n",
    "\n",
    "Checks normality assumption:\n",
    "- Points on diagonal: Normal\n",
    "- Deviations at tails: Heavy or light tails\n",
    "- S-shape: Skewed distribution\n",
    "\n",
    "**Plot 4: Scale-Location Plot**\n",
    "\n",
    "Alternative check for homoskedasticity:\n",
    "- Plots $\\sqrt{|\\text{residuals}|}$ vs fitted values\n",
    "- Horizontal line suggests constant variance\n",
    "\n",
    "**Example: Comprehensive Residual Analysis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7f62b11c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-20T11:12:21.620415Z",
     "iopub.status.busy": "2025-10-20T11:12:21.620335Z",
     "iopub.status.idle": "2025-10-20T11:12:21.759440Z",
     "shell.execute_reply": "2025-10-20T11:12:21.759147Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/rg/vmn_nq41613gkxt0_9spwzx80000gp/T/ipykernel_8305/995074403.py:42: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  plt.show()\n"
     ]
    }
   ],
   "source": [
    "# Estimate model\n",
    "hprice1 = woo.data('hprice1')\n",
    "house_model = smf.ols('price ~ lotsize + sqrft + bdrms', data=hprice1).fit()\n",
    "\n",
    "# Get residuals and fitted values\n",
    "residuals = house_model.resid\n",
    "fitted = house_model.fittedvalues\n",
    "standardized_resid = house_model.resid_pearson\n",
    "\n",
    "# Create 2x2 subplot for diagnostics\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "\n",
    "# Plot 1: Residuals vs Fitted\n",
    "axes[0, 0].scatter(fitted, residuals, alpha=0.6)\n",
    "axes[0, 0].axhline(y=0, color='r', linestyle='--')\n",
    "axes[0, 0].set_xlabel('Fitted Values')\n",
    "axes[0, 0].set_ylabel('Residuals')\n",
    "axes[0, 0].set_title('Residuals vs Fitted')\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 2: Q-Q Plot for normality\n",
    "stats.probplot(residuals, dist=\"norm\", plot=axes[0, 1])\n",
    "axes[0, 1].set_title('Normal Q-Q Plot')\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 3: Scale-Location (sqrt of standardized residuals)\n",
    "axes[1, 0].scatter(fitted, np.sqrt(np.abs(standardized_resid)), alpha=0.6)\n",
    "axes[1, 0].set_xlabel('Fitted Values')\n",
    "axes[1, 0].set_ylabel('$\\sqrt{|Standardized Residuals|}$')\n",
    "axes[1, 0].set_title('Scale-Location')\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 4: Residuals vs sqrft (key predictor)\n",
    "axes[1, 1].scatter(hprice1['sqrft'], residuals, alpha=0.6)\n",
    "axes[1, 1].axhline(y=0, color='r', linestyle='--')\n",
    "axes[1, 1].set_xlabel('Square Footage')\n",
    "axes[1, 1].set_ylabel('Residuals')\n",
    "axes[1, 1].set_title('Residuals vs Square Footage')\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec99710a",
   "metadata": {},
   "source": [
    "**How to Interpret:**\n",
    "\n",
    "1. **Funnel in residuals vs fitted**  Heteroskedasticity (use robust SEs, Chapter 8)\n",
    "2. **Curved pattern**  Add quadratic/interaction terms\n",
    "3. **Deviations from Q-Q diagonal**  Non-normal errors (okay if $n$ is large)\n",
    "4. **Few extreme outliers**  Check for data errors or influential observations\n",
    "\n",
    "### 6.4.3 Identifying Influential Observations\n",
    "\n",
    "Some observations have disproportionate influence on regression results. Key diagnostics:\n",
    "\n",
    "**1. Leverage**: How far $x_i$ is from $\\bar{x}$\n",
    "- High leverage $\\to$ observation can pull regression line\n",
    "\n",
    "**2. Studentized Residuals**: Residuals standardized by their standard error\n",
    "- $|r_i| > 3$ suggests outlier\n",
    "\n",
    "**3. Cook's Distance**: Combined measure of leverage and residual size\n",
    "- $D_i > 4/n$ suggests influential observation\n",
    "- $D_i > 1$ is very influential\n",
    "\n",
    "**Example: Influence Diagnostics**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6da76324",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-20T11:12:21.760818Z",
     "iopub.status.busy": "2025-10-20T11:12:21.760732Z",
     "iopub.status.idle": "2025-10-20T11:12:21.775260Z",
     "shell.execute_reply": "2025-10-20T11:12:21.775004Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Observation</th>\n",
       "      <th>Leverage</th>\n",
       "      <th>Cooks D</th>\n",
       "      <th>Stud. Resid</th>\n",
       "      <th>Influential</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>76</td>\n",
       "      <td>0.8427</td>\n",
       "      <td>31.7505</td>\n",
       "      <td>-4.8682</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>72</td>\n",
       "      <td>0.1371</td>\n",
       "      <td>0.3451</td>\n",
       "      <td>2.9471</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>41</td>\n",
       "      <td>0.0999</td>\n",
       "      <td>0.3397</td>\n",
       "      <td>3.4995</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>62</td>\n",
       "      <td>0.2191</td>\n",
       "      <td>0.1141</td>\n",
       "      <td>1.2752</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>47</td>\n",
       "      <td>0.1357</td>\n",
       "      <td>0.1056</td>\n",
       "      <td>-1.6403</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Observation  Leverage  Cooks D  Stud. Resid  Influential\n",
       "76           76    0.8427  31.7505      -4.8682         True\n",
       "72           72    0.1371   0.3451       2.9471         True\n",
       "41           41    0.0999   0.3397       3.4995         True\n",
       "62           62    0.2191   0.1141       1.2752         True\n",
       "47           47    0.1357   0.1056      -1.6403         True"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/rg/vmn_nq41613gkxt0_9spwzx80000gp/T/ipykernel_8305/3454815983.py:31: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  plt.show()\n"
     ]
    }
   ],
   "source": [
    "# Calculate influence measures\n",
    "from statsmodels.stats.outliers_influence import OLSInfluence\n",
    "\n",
    "influence = OLSInfluence(house_model)\n",
    "leverage = influence.hat_matrix_diag\n",
    "cooks_d = influence.cooks_distance[0]\n",
    "studentized_resid = influence.resid_studentized_internal\n",
    "\n",
    "# Identify influential observations\n",
    "influential = pd.DataFrame({\n",
    "    'Observation': range(len(leverage)),\n",
    "    'Leverage': leverage,\n",
    "    'Cooks D': cooks_d,\n",
    "    'Stud. Resid': studentized_resid,\n",
    "    'Influential': (cooks_d > 4/len(leverage)) | (np.abs(studentized_resid) > 3)\n",
    "})\n",
    "\n",
    "# Show top 5 most influential\n",
    "top_influential = influential.nlargest(5, 'Cooks D')\n",
    "display(top_influential.round(4))\n",
    "\n",
    "# Plot Cook's Distance\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.stem(range(len(cooks_d)), cooks_d, markerfmt=',', basefmt=' ')\n",
    "plt.axhline(y=4/len(leverage), color='r', linestyle='--', label='Threshold (4/n)')\n",
    "plt.xlabel('Observation Index')\n",
    "plt.ylabel(\"Cook's Distance\")\n",
    "plt.title(\"Influence Plot: Cook's Distance\")\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41044900",
   "metadata": {},
   "source": [
    "**What to Do with Influential Observations:**\n",
    "\n",
    "1. **Check for data errors**: Typos, incorrect units, etc.\n",
    "2. **Investigate substantively**: Are they legitimate unusual cases?\n",
    "3. **Report sensitivity**: Show results with and without influential observations\n",
    "4. **Use robust methods**: Robust regression (less sensitive to outliers)\n",
    "5. **DON'T automatically delete**: May represent important heterogeneity\n",
    "\n",
    ":::{important} Residual Analysis Best Practices\n",
    ":class: dropdown\n",
    "\n",
    "**Always**:\n",
    "- Plot residuals vs fitted values (most important!)\n",
    "- Check for a few influential observations\n",
    "- Investigate any clear patterns\n",
    "\n",
    "**Often**:\n",
    "- Plot residuals vs key predictors\n",
    "- Check Q-Q plot if assuming normality\n",
    "- Calculate Cook's distance for leverage\n",
    "\n",
    "**Sometimes**:\n",
    "- Use formal tests (Breusch-Pagan, White for heteroskedasticity)\n",
    "- Apply transformations based on residual patterns\n",
    "- Refit model excluding highly influential observations\n",
    "\n",
    "**Never**:\n",
    "- Delete observations just to improve R-squared\n",
    "- Ignore systematic patterns in residuals\n",
    "- Assume residuals are fine without checking\n",
    ":::\n",
    "\n",
    "## Chapter Summary\n",
    "\n",
    "This chapter covered essential practical issues in multiple regression analysis, focusing on model specification, functional form, and diagnostic checking. These tools help you build better models and avoid common pitfalls.\n",
    "\n",
    "**Key Concepts:**\n",
    "\n",
    "**1. Effects of Data Scaling (Section 6.1.1-6.1.2)**:\n",
    "- Multiplying $y$ by constant scales $\\hat{\\beta}$, $\\text{se}(\\hat{\\beta})$, and $SSR$ by same constant\n",
    "- Multiplying $x_j$ by constant scales $\\hat{\\beta}_j$ and $\\text{se}(\\hat{\\beta}_j)$ by reciprocal\n",
    "- **t-statistics and R-squared are invariant** to scaling\n",
    "- **Standardized coefficients** (beta coefficients) allow comparing importance across variables\n",
    "\n",
    "**2. Functional Form (Section 6.1.3-6.1.6)**:\n",
    "- **Log transformations**: Interpret coefficients as percentage effects, invariant to scaling\n",
    "- **Log-linear**: $\\beta$ = percentage change in $y$ per unit change in $x$\n",
    "- **Log-log**: $\\beta$ = elasticity (percentage change in $y$ per 1% change in $x$)\n",
    "- **Quadratic terms**: Allow nonlinear (U-shaped or inverted-U) relationships\n",
    "- **Interaction terms**: Allow effect of $x_1$ to depend on level of $x_2$\n",
    "\n",
    "**3. Goodness-of-Fit and Model Selection (Section 6.3)**:\n",
    "- **Adjusted R-squared** penalizes adding variables, prefer for model comparison\n",
    "- **AIC and BIC**: Lower is better, BIC penalizes complexity more heavily\n",
    "- **Too many variables**: Causes multicollinearity, overfitting, imprecise estimates\n",
    "- **Occam's Razor**: Prefer simpler models when fit is similar\n",
    "\n",
    "**4. Special Issues with Logs (Section 6.3.4)**:\n",
    "- **log(1 + y)** has interpretation problems - avoid when possible\n",
    "- **Inverse hyperbolic sine** better for handling zeros\n",
    "- **Predicting levels from log(y)**: Need retransformation correction $\\exp(\\hat{\\sigma}^2/2)$\n",
    "\n",
    "**5. Prediction (Section 6.2)**:\n",
    "- **Confidence interval** for $E(y|x)$: Narrower, estimates mean\n",
    "- **Prediction interval** for new $y$: Wider, accounts for individual variation\n",
    "- Prediction intervals always wider than confidence intervals by factor of $\\sqrt{1 + \\text{leverage}}$\n",
    "\n",
    "**6. Residual Analysis (Section 6.4)**:\n",
    "- **Residual plots** reveal violations of assumptions\n",
    "- **Patterns** suggest heteroskedasticity or functional form problems\n",
    "- **Cook's distance** identifies influential observations\n",
    "- Always check residuals before trusting results!\n",
    "\n",
    "**Practical Workflow for Model Building:**\n",
    "\n",
    "1. **Start simple**: Begin with linear specification, key variables\n",
    "2. **Check residuals**: Look for patterns suggesting needed transformations\n",
    "3. **Add complexity thoughtfully**: Quadratics, interactions, logs as theory/diagnostics suggest\n",
    "4. **Compare models**: Use adjusted R-squared, AIC, BIC\n",
    "5. **Test restrictions**: F-tests for joint significance of added terms\n",
    "6. **Validate**: Check out-of-sample performance, sensitivity to outliers\n",
    "7. **Interpret carefully**: Remember scaling, functional form implications\n",
    "\n",
    "**Common Mistakes to Avoid:**\n",
    "\n",
    "-  Including too many variables (overfitting)\n",
    "-  Chasing high R-squared without theory\n",
    "-  Ignoring residual patterns\n",
    "-  Misinterpreting log coefficients\n",
    "-  Using prediction intervals when you need confidence intervals (or vice versa)\n",
    "-  Deleting influential observations without investigation\n",
    "\n",
    "**Connections to Other Chapters:**\n",
    "\n",
    "- **Chapter 3**: Bad controls, multicollinearity, functional form as specification issues\n",
    "- **Chapter 5**: Model selection relates to consistency (correct specification)\n",
    "- **Chapter 8**: Heteroskedasticity revealed by residual analysis, affects prediction intervals\n",
    "- **Chapter 9**: RESET test for functional form, proxy variables\n",
    "\n",
    "**Looking Forward:**\n",
    "\n",
    "- **Chapter 7**: Dummy variables (discrete functional form)\n",
    "- **Chapter 8**: Heteroskedasticity (variance patterns in residuals)  \n",
    "- **Chapter 9**: Specification tests (formal checks of functional form)\n",
    "\n",
    "**The Bottom Line:**\n",
    "\n",
    "Regression is an art as much as a science. Good practice combines:\n",
    "- **Economic theory**: What variables and functional forms make sense?\n",
    "- **Diagnostic checking**: Do residuals reveal problems?\n",
    "- **Model comparison**: Which specification fits best without overfitting?\n",
    "- **Robust inference**: Use methods that work even when assumptions fail\n",
    "\n",
    "Master these tools and you'll build better, more reliable regression models!"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "notebooks//ipynb,markdown//md,scripts//py"
  },
  "kernelspec": {
   "display_name": "merino",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
